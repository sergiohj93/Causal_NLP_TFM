{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0088923-9667-4588-860b-7776ca55856a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification, BertModel, BertForSequenceClassification, BertTokenizer\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Concatenate, GlobalAveragePooling1D\n",
    "from keras import backend as K\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import tensorflow as tf\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ddeff-cef7-4935-950e-bdc838804930",
   "metadata": {},
   "source": [
    "# Training of the ITE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138e16f-736b-4128-805c-8875a1868bea",
   "metadata": {},
   "source": [
    "## Loading the embeddings as the inputs and the ITE as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a15ba54-4b5a-4588-987c-573067a1aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment and general embeddings of the factuals\n",
    "sent_fact_outs = np.load('outs/counterfactuals/sent_fact_outs.npy')\n",
    "gen_fact_outs = np.load('outs/counterfactuals/gen_fact_outs.npy')\n",
    "conc_fact = np.concatenate([sent_fact_outs,gen_fact_outs],axis=1)\n",
    "\n",
    "#Copying the factuals in order to have one for each counterfactual.\n",
    "n_cf = 5\n",
    "fact_n_cf = [] \n",
    "for i in range(len(conc_fact)):\n",
    "    for j in range(n_cf):\n",
    "        fact_n_cf.append(conc_fact[i])\n",
    "fact_n_cf = np.array(fact_n_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9951c7e-cf76-4ff5-8bdb-b115fa16aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the counterfactuals\n",
    "sent_cf_off_outs = np.load('outs/counterfactuals/sent_cf_off_outs.npy')\n",
    "gen_cf_off_outs = np.load('outs/counterfactuals/gen_cf_off_outs.npy')\n",
    "conc_cf = np.concatenate([sent_cf_off_outs,gen_cf_off_outs],axis=1)\n",
    "\n",
    "fact_n_cf = np.concatenate([fact_n_cf,conc_cf],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b543b2-2f32-41b5-8e0f-cde7c0a03afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITE_peace = np.load('outs/counterfactuals/ITE_peace.npy')\n",
    "\n",
    "#Duplicate the ITEs to match the concatenation of factuals_x_5 and counterfactuals\n",
    "ITE_peace = np.concatenate([ITE_peace,ITE_peace],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8027b-7ac4-4bea-81cd-2537440aae0c",
   "metadata": {},
   "source": [
    "## Training the model to evaluate the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bde8fbb-62b8-4863-8d4a-f953e7fb9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "        return np.mean(np.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfafbab-fe71-42e6-9980-3451933982cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0bffaf-6db8-4247-b53a-5d86c9223ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_train,fact_test,ITE_train,ITE_test = train_test_split(fact_n_cf,ITE_peace,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ae1ab6-c190-4563-b539-21df5f1f699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "602/602 [==============================] - 2s 2ms/step - loss: 0.0948 - val_loss: 0.0771\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0763 - val_loss: 0.0791\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0700\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0655\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0603 - val_loss: 0.0665\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0615\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0529 - val_loss: 0.0632\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0590\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0488 - val_loss: 0.0600\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0461 - val_loss: 0.0576\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0436 - val_loss: 0.0586\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0426 - val_loss: 0.0546\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0407 - val_loss: 0.0627\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0396 - val_loss: 0.0590\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0390 - val_loss: 0.0562\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0556\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0354 - val_loss: 0.0570\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0550\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0337 - val_loss: 0.0558\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0328 - val_loss: 0.0577\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0936 - val_loss: 0.0820\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0771 - val_loss: 0.0740\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0699 - val_loss: 0.0678\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0715\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0605 - val_loss: 0.0660\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0570 - val_loss: 0.0638\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0616\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0591\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0478 - val_loss: 0.0598\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0458 - val_loss: 0.0579\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0442 - val_loss: 0.0572\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0416 - val_loss: 0.0559\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0408 - val_loss: 0.0588\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0388 - val_loss: 0.0564\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0371 - val_loss: 0.0599\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0360 - val_loss: 0.0545\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0538\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0339 - val_loss: 0.0586\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0327 - val_loss: 0.0544\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0316 - val_loss: 0.0540\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0933 - val_loss: 0.0802\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0771 - val_loss: 0.0752\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0713 - val_loss: 0.0742\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0711\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0619 - val_loss: 0.0642\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0579 - val_loss: 0.0626\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0541 - val_loss: 0.0695\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0523 - val_loss: 0.0588\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0603\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0478 - val_loss: 0.0586\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0458 - val_loss: 0.0615\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0434 - val_loss: 0.0574\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0572\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.0583\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0575\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0368 - val_loss: 0.0559\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0565\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0350 - val_loss: 0.0679\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0344 - val_loss: 0.0592\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0331 - val_loss: 0.0546\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 2s 2ms/step - loss: 0.0952 - val_loss: 0.0743\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0774 - val_loss: 0.0770\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0703 - val_loss: 0.0702\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0659\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0617 - val_loss: 0.0655\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0579 - val_loss: 0.0648\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0544 - val_loss: 0.0616\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0618\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0484 - val_loss: 0.0600\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0465 - val_loss: 0.0593\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0439 - val_loss: 0.0574\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0422 - val_loss: 0.0558\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0404 - val_loss: 0.0574\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0391 - val_loss: 0.0567\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0381 - val_loss: 0.0530\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0361 - val_loss: 0.0537\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0529\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0342 - val_loss: 0.0568\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0330 - val_loss: 0.0553\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0322 - val_loss: 0.0537\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0924 - val_loss: 0.0772\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0764 - val_loss: 0.0742\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0711 - val_loss: 0.0685\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0664 - val_loss: 0.0700\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0613 - val_loss: 0.0677\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0579 - val_loss: 0.0643\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0535 - val_loss: 0.0629\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0587\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0486 - val_loss: 0.0622\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0459 - val_loss: 0.0578\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0442 - val_loss: 0.0619\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0422 - val_loss: 0.0608\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0408 - val_loss: 0.0565\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0394 - val_loss: 0.0555\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0556\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0364 - val_loss: 0.0577\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0353 - val_loss: 0.0530\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0346 - val_loss: 0.0530\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0333 - val_loss: 0.0533\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0327 - val_loss: 0.0531\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0943 - val_loss: 0.0759\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0764 - val_loss: 0.0788\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0693 - val_loss: 0.0713\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0649 - val_loss: 0.0649\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0602 - val_loss: 0.0718\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0572 - val_loss: 0.0699\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0530 - val_loss: 0.0648\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0511 - val_loss: 0.0594\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0486 - val_loss: 0.0571\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0469 - val_loss: 0.0570\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0445 - val_loss: 0.0588\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0430 - val_loss: 0.0560\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0420 - val_loss: 0.0558\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0563\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0392 - val_loss: 0.0550\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0377 - val_loss: 0.0546\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0368 - val_loss: 0.0588\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.0553\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0345 - val_loss: 0.0555\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0335 - val_loss: 0.0541\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0944 - val_loss: 0.0786\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0771 - val_loss: 0.0735\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0699 - val_loss: 0.0717\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0650 - val_loss: 0.0700\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0608 - val_loss: 0.0648\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0608\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0530 - val_loss: 0.0624\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0586\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0480 - val_loss: 0.0568\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0450 - val_loss: 0.0608\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0433 - val_loss: 0.0595\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0413 - val_loss: 0.0565\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0394 - val_loss: 0.0545\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0573\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0364 - val_loss: 0.0564\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0351 - val_loss: 0.0543\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0344 - val_loss: 0.0532\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0332 - val_loss: 0.0524\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0522\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0313 - val_loss: 0.0554\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 2s 2ms/step - loss: 0.0907 - val_loss: 0.0787\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0769 - val_loss: 0.0729\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0692 - val_loss: 0.0679\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0639 - val_loss: 0.0684\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0600 - val_loss: 0.0672\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0554 - val_loss: 0.0621\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.0607\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0490 - val_loss: 0.0572\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0468 - val_loss: 0.0562\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0441 - val_loss: 0.0563\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0418 - val_loss: 0.0561\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0398 - val_loss: 0.0550\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0534\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0554\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0353 - val_loss: 0.0536\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0347 - val_loss: 0.0528\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0328 - val_loss: 0.0514\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0317 - val_loss: 0.0514\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0535\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0541\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0934 - val_loss: 0.0804\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0776 - val_loss: 0.0739\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0705 - val_loss: 0.0709\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0660 - val_loss: 0.0712\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0606 - val_loss: 0.0682\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0650\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0540 - val_loss: 0.0660\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0586\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0481 - val_loss: 0.0610\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0462 - val_loss: 0.0600\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0438 - val_loss: 0.0590\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0421 - val_loss: 0.0603\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0404 - val_loss: 0.0565\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0392 - val_loss: 0.0547\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0379 - val_loss: 0.0546\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0566\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0354 - val_loss: 0.0594\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0338 - val_loss: 0.0534\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0329 - val_loss: 0.0549\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0324 - val_loss: 0.0616\n",
      "Epoch 1/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0960 - val_loss: 0.0797\n",
      "Epoch 2/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0761 - val_loss: 0.0717\n",
      "Epoch 3/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0703 - val_loss: 0.0695\n",
      "Epoch 4/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0652 - val_loss: 0.0683\n",
      "Epoch 5/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0611 - val_loss: 0.0742\n",
      "Epoch 6/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0576 - val_loss: 0.0633\n",
      "Epoch 7/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0541 - val_loss: 0.0613\n",
      "Epoch 8/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0605\n",
      "Epoch 9/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0608\n",
      "Epoch 10/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0466 - val_loss: 0.0611\n",
      "Epoch 11/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0447 - val_loss: 0.0583\n",
      "Epoch 12/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.0565\n",
      "Epoch 13/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0410 - val_loss: 0.0577\n",
      "Epoch 14/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0393 - val_loss: 0.0603\n",
      "Epoch 15/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0541\n",
      "Epoch 16/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0566\n",
      "Epoch 17/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0542\n",
      "Epoch 18/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0343 - val_loss: 0.0551\n",
      "Epoch 19/20\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0333 - val_loss: 0.0536\n",
      "Epoch 20/20\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0561\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf\n",
    "best_ITE_model = None\n",
    "for i in range(n_runs):\n",
    "    ITE_model = Sequential([\n",
    "              Flatten(),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(64, activation='relu'),\n",
    "              Dense(1, activation='tanh')\n",
    "          ])\n",
    "    ITE_model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    history = ITE_model.fit(fact_train,ITE_train,epochs=20,batch_size=32,validation_split=0.1)\n",
    "    \n",
    "    # Get the last validation loss\n",
    "    last_val_loss = history.history['val_loss'][-1]\n",
    "    # Compare with the best validation loss\n",
    "    if last_val_loss < best_val_loss:\n",
    "        best_val_loss = last_val_loss\n",
    "        best_ITE_model = ITE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09a7215-5014-4117-a1d4-f1660a35365b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 1s 891us/step\n",
      "287/287 [==============================] - 0s 842us/step\n"
     ]
    }
   ],
   "source": [
    "ITE_pred_train = np.squeeze(best_ITE_model.predict(fact_train))\n",
    "ITE_pred_test = np.squeeze(best_ITE_model.predict(fact_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c24308-3489-41d0-af9b-f1ae8f0f38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.032715544\n",
      "MSE test: 0.05406826\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE train:\",mse(ITE_train,ITE_pred_train))\n",
    "print(\"MSE test:\",mse(ITE_test,ITE_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e920d1e-d514-48be-b23a-4db3b77072df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE pred. train: 0.29615417\n",
      "ATE pred. test: 0.30305767\n"
     ]
    }
   ],
   "source": [
    "print(\"ATE pred. train:\",np.mean(ITE_pred_train))\n",
    "print(\"ATE pred. test:\",np.mean(ITE_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca39ea-7d87-43cd-9368-16850b277d89",
   "metadata": {},
   "source": [
    "## Training the model with all the data (training and test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f9812d-00e2-486d-b5b9-c9c22a499867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0952 - val_loss: 0.0890\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0737 - val_loss: 0.0827\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0668 - val_loss: 0.0780\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0619 - val_loss: 0.0759\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0578 - val_loss: 0.0771\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0538 - val_loss: 0.0769\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0820\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0484 - val_loss: 0.0799\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0461 - val_loss: 0.0830\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0781\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0418 - val_loss: 0.0752\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0779\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0390 - val_loss: 0.0823\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0823\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0807\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0864\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0354 - val_loss: 0.0820\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0810\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0805\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0804\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0324 - val_loss: 0.0813\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0320 - val_loss: 0.0806\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0796\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0841\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0852\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0893 - val_loss: 0.0820\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0829\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0675 - val_loss: 0.0822\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0617 - val_loss: 0.0869\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0579 - val_loss: 0.0806\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0542 - val_loss: 0.0822\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0813\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0482 - val_loss: 0.0809\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0456 - val_loss: 0.0818\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0844\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0836\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0824\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0391 - val_loss: 0.0809\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0843\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0371 - val_loss: 0.0827\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0356 - val_loss: 0.0813\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0351 - val_loss: 0.0789\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0339 - val_loss: 0.0826\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.0860\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0810\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0322 - val_loss: 0.0843\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0830\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0812\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0304 - val_loss: 0.0822\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0304 - val_loss: 0.0876\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0946 - val_loss: 0.0823\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0736 - val_loss: 0.0783\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0665 - val_loss: 0.0767\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0614 - val_loss: 0.0805\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0790\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0533 - val_loss: 0.0772\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0504 - val_loss: 0.0839\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0472 - val_loss: 0.0797\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0828\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0432 - val_loss: 0.0843\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0407 - val_loss: 0.0778\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0400 - val_loss: 0.0790\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0385 - val_loss: 0.0820\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0827\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0811\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0350 - val_loss: 0.0782\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0341 - val_loss: 0.0808\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0328 - val_loss: 0.0824\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0799\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0793\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0884\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0308 - val_loss: 0.0825\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0302 - val_loss: 0.0806\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0297 - val_loss: 0.0803\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0294 - val_loss: 0.0855\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0872 - val_loss: 0.0824\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0730 - val_loss: 0.0796\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0653 - val_loss: 0.0770\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0796\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0556 - val_loss: 0.0815\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0516 - val_loss: 0.0843\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0481 - val_loss: 0.0825\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0463 - val_loss: 0.0811\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0436 - val_loss: 0.0750\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0805\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0770\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0388 - val_loss: 0.0781\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0373 - val_loss: 0.0784\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.0769\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0817\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0342 - val_loss: 0.0798\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0788\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0323 - val_loss: 0.0773\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0317 - val_loss: 0.0799\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0311 - val_loss: 0.0788\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0306 - val_loss: 0.0793\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0801\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0296 - val_loss: 0.0808\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0792\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0772\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0964 - val_loss: 0.0786\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0731 - val_loss: 0.0778\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0650 - val_loss: 0.0774\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0606 - val_loss: 0.0802\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0553 - val_loss: 0.0768\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0820\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0797\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0471 - val_loss: 0.0768\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0442 - val_loss: 0.0780\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.0783\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0414 - val_loss: 0.0816\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0394 - val_loss: 0.0777\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0379 - val_loss: 0.0823\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0368 - val_loss: 0.0757\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0361 - val_loss: 0.0776\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0348 - val_loss: 0.0782\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0826\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0801\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0329 - val_loss: 0.0839\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0792\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0316 - val_loss: 0.0782\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0836\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0305 - val_loss: 0.0827\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0299 - val_loss: 0.0795\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0298 - val_loss: 0.0838\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0874 - val_loss: 0.0879\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0721 - val_loss: 0.0779\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0653 - val_loss: 0.0758\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0595 - val_loss: 0.0844\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0557 - val_loss: 0.0825\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0531 - val_loss: 0.0753\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0495 - val_loss: 0.0787\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0473 - val_loss: 0.0801\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0448 - val_loss: 0.0786\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0425 - val_loss: 0.0808\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0412 - val_loss: 0.0770\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0398 - val_loss: 0.0763\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0384 - val_loss: 0.0802\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0787\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0776\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0762\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0786\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0339 - val_loss: 0.0781\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0331 - val_loss: 0.0810\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0329 - val_loss: 0.0789\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0320 - val_loss: 0.0803\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0315 - val_loss: 0.0799\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0308 - val_loss: 0.0800\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0809\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0298 - val_loss: 0.0835\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0904 - val_loss: 0.0824\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0804\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0858\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0613 - val_loss: 0.0768\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0565 - val_loss: 0.0822\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0539 - val_loss: 0.0775\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0499 - val_loss: 0.0761\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0479 - val_loss: 0.0804\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0452 - val_loss: 0.0800\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0437 - val_loss: 0.0799\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0417 - val_loss: 0.0826\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0805\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0389 - val_loss: 0.0833\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0379 - val_loss: 0.0784\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0367 - val_loss: 0.0823\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0358 - val_loss: 0.0808\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0348 - val_loss: 0.0811\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0821\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0331 - val_loss: 0.0790\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0327 - val_loss: 0.0831\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0318 - val_loss: 0.0807\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0313 - val_loss: 0.0810\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0308 - val_loss: 0.0801\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0304 - val_loss: 0.0802\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0298 - val_loss: 0.0807\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0897 - val_loss: 0.0896\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0814\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0666 - val_loss: 0.0783\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0617 - val_loss: 0.0796\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0577 - val_loss: 0.0797\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0542 - val_loss: 0.0802\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0514 - val_loss: 0.0804\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0489 - val_loss: 0.0793\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0474 - val_loss: 0.0812\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0454 - val_loss: 0.0816\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0438 - val_loss: 0.0795\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0422 - val_loss: 0.0873\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0840\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0399 - val_loss: 0.0861\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0389 - val_loss: 0.0830\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0378 - val_loss: 0.0838\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0846\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0361 - val_loss: 0.0841\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0352 - val_loss: 0.0841\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0348 - val_loss: 0.0827\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0341 - val_loss: 0.0857\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0837\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0328 - val_loss: 0.0852\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0326 - val_loss: 0.0816\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0318 - val_loss: 0.0827\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0932 - val_loss: 0.0856\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0749 - val_loss: 0.0843\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0678 - val_loss: 0.0830\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0628 - val_loss: 0.0773\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0583 - val_loss: 0.0824\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0552 - val_loss: 0.0807\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0820\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0495 - val_loss: 0.0767\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0474 - val_loss: 0.0785\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0455 - val_loss: 0.0783\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0438 - val_loss: 0.0782\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0422 - val_loss: 0.0776\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0409 - val_loss: 0.0782\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0399 - val_loss: 0.0774\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.0775\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0382 - val_loss: 0.0837\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0773\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0365 - val_loss: 0.0804\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0356 - val_loss: 0.0795\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0348 - val_loss: 0.0778\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0345 - val_loss: 0.0821\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0333 - val_loss: 0.0805\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0330 - val_loss: 0.0816\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0325 - val_loss: 0.0828\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.0783\n",
      "Epoch 1/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0877 - val_loss: 0.0847\n",
      "Epoch 2/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0732 - val_loss: 0.0839\n",
      "Epoch 3/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0657 - val_loss: 0.0768\n",
      "Epoch 4/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0594 - val_loss: 0.0790\n",
      "Epoch 5/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0554 - val_loss: 0.0830\n",
      "Epoch 6/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0519 - val_loss: 0.0801\n",
      "Epoch 7/25\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0496 - val_loss: 0.0810\n",
      "Epoch 8/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0470 - val_loss: 0.0771\n",
      "Epoch 9/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0448 - val_loss: 0.0811\n",
      "Epoch 10/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0433 - val_loss: 0.0814\n",
      "Epoch 11/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0827\n",
      "Epoch 12/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0401 - val_loss: 0.0814\n",
      "Epoch 13/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0389 - val_loss: 0.0832\n",
      "Epoch 14/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0816\n",
      "Epoch 15/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0370 - val_loss: 0.0793\n",
      "Epoch 16/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0356 - val_loss: 0.0895\n",
      "Epoch 17/25\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0352 - val_loss: 0.0826\n",
      "Epoch 18/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0346 - val_loss: 0.0820\n",
      "Epoch 19/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0337 - val_loss: 0.0826\n",
      "Epoch 20/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0326 - val_loss: 0.0820\n",
      "Epoch 21/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0325 - val_loss: 0.0824\n",
      "Epoch 22/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0320 - val_loss: 0.0830\n",
      "Epoch 23/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0315 - val_loss: 0.0849\n",
      "Epoch 24/25\n",
      "860/860 [==============================] - 1s 2ms/step - loss: 0.0309 - val_loss: 0.0802\n",
      "Epoch 25/25\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 0.0305 - val_loss: 0.0830\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf\n",
    "best_ITE_model = None\n",
    "for i in range(n_runs):\n",
    "    ITE_model = Sequential([\n",
    "              Flatten(),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(64, activation='relu'),\n",
    "              Dense(1, activation='tanh')\n",
    "          ])\n",
    "    ITE_model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    history = ITE_model.fit(fact_n_cf,ITE_peace,epochs=25,batch_size=32,validation_split=0.1)\n",
    "    \n",
    "    # Get the last validation loss\n",
    "    last_val_loss = history.history['val_loss'][-1]\n",
    "    # Compare with the best validation loss\n",
    "    if last_val_loss < best_val_loss:\n",
    "        best_val_loss = last_val_loss\n",
    "        best_ITE_model = ITE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df208ccd-bcfb-4e68-9538-fa659379a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Prediction of the factuals\n",
    "ITE_pred_fact = np.squeeze(best_ITE_model.predict(conc_fact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8fa636-dc07-483c-9c5a-ae6767e2619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ITE_model/models/ITE_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_ITE_model.save('models/ITE_model/models/ITE_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4146d-edce-4ea1-bc08-33436664bf6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ATE of the factuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4b7824-15b8-45c9-908d-50f386debd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 0.29615065\n"
     ]
    }
   ],
   "source": [
    "print(\"ATE:\",np.mean(ITE_pred_fact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b7c897-3f5b-4821-a5d9-f2eb5d9da31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxyElEQVR4nO3df1jUZb7/8dcIwyAukGgykKTUoTwFdQzLX3vCTcA8kXV5XbkdXbOOp6XL8sSql6vHq+8OWwfLPal7sDrZReqlh7WrU+zudWkJXpuUB9uQdDe1rHZd04I4uQgYNExwf//o63wbQWP4NTfM83FdXDr33PP53O+3n/nw8sMM4zDGGAEAAFhsWKgXAAAA8F0ILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA60WGegE90dHRoc8++0yxsbFyOByhXg4AAOgGY4yam5uVnJysYcOCu2YyKAPLZ599ppSUlFAvAwAA9MCpU6c0duzYoB4zKANLbGyspG8KjouLC8kafD6fysvLlZubK6fTGZI1hFK41y/RA4kehHv9Ej0I9/ql4HrQ1NSklJQU//fxYAzKwHL+x0BxcXEhDSwxMTGKi4sLy4M03OuX6IFED8K9fokehHv9Us960JOXc/CiWwAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsF1RgGT9+vBwOR6evhx9+WJJkjJHH41FycrKGDx+uGTNm6OjRowHb8Hq9Wrp0qUaPHq0RI0Zozpw5On36dN9VBAAAhpygAkt1dbVqa2v9XxUVFZKke+65R5K0bt06rV+/Xps2bVJ1dbXcbrdycnLU3Nzs30ZBQYHKysq0c+dO7d+/X+fOnVNeXp7a29v7sCwAADCURAYz+fLLLw+4/eSTT+rqq69WVlaWjDHauHGj1qxZo7lz50qStm3bpsTERJWWlio/P1+NjY0qKSnR9u3blZ2dLUnasWOHUlJStHfvXs2aNauPygIwmI1ftSvUS+gWV4TRulukdM8eHf+3vFAvBxjSggos39bW1qYdO3Zo2bJlcjgc+vOf/6y6ujrl5ub657hcLmVlZamqqkr5+fmqqamRz+cLmJOcnKz09HRVVVVdNLB4vV55vV7/7aamJkmSz+eTz+fraQm9cn6/odp/qIV7/RI9kPqvB64I06fb6y+uYcb/Z7geB+H+PAj3+qXgetCbPvU4sPz617/W2bNndf/990uS6urqJEmJiYkB8xITE3Xy5En/nKioKI0cObLTnPOP78ratWtVWFjYaby8vFwxMTE9LaFPnP+xWLgK9/oleiD1fQ/W3dKnm+t3j0/q0O7du0O9jJAK9+dBuNcvda8HLS0tPd5+jwNLSUmJZs+ereTk5IBxh8MRcNsY02nsQt81Z/Xq1Vq2bJn/dlNTk1JSUpSbm6u4uLgerL73fD6fKioqlJOTI6fTGZI1hFK41y/RA6n/epDu2dNn2+pPrmFGj0/q0GMHh6nm/9we6uWERLg/D8K9fim4Hpz/CUlP9CiwnDx5Unv37tWrr77qH3O73ZK+uYqSlJTkH6+vr/dfdXG73Wpra1NDQ0PAVZb6+npNmzbtovtzuVxyuVydxp1OZ8gPEBvWEErhXr9ED6S+74G3/dL/ybGNt8PBMRDmz4Nwr1/qXg9606Me/R6WLVu2aMyYMbrjjjv8Y6mpqXK73QGXhNra2lRZWekPI5mZmXI6nQFzamtrdeTIkUsGFgAAEN6CvsLS0dGhLVu2aNGiRYqM/P8PdzgcKigoUFFRkdLS0pSWlqaioiLFxMRo/vz5kqT4+HgtXrxYy5cv16hRo5SQkKAVK1YoIyPD/64hAACACwUdWPbu3atPPvlE//RP/9TpvpUrV6q1tVVLlixRQ0ODJk+erPLycsXGxvrnbNiwQZGRkZo3b55aW1s1c+ZMbd26VREREb2rBAAADFlBB5bc3FwZ0/VbDh0Ohzwejzwez0UfHx0dreLiYhUXFwe7awAAEKb4LCEAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWC/ozxICMLiMX7Wr37btijBad4uU7tkjb7uj3/YDAFxhAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9YIOLJ9++ql+9KMfadSoUYqJidHf/d3fqaamxn+/MUYej0fJyckaPny4ZsyYoaNHjwZsw+v1aunSpRo9erRGjBihOXPm6PTp072vBgAADElBBZaGhgZNnz5dTqdTr732mo4dO6ann35al112mX/OunXrtH79em3atEnV1dVyu93KyclRc3Ozf05BQYHKysq0c+dO7d+/X+fOnVNeXp7a29v7rDAAADB0RAYz+amnnlJKSoq2bNniHxs/frz/78YYbdy4UWvWrNHcuXMlSdu2bVNiYqJKS0uVn5+vxsZGlZSUaPv27crOzpYk7dixQykpKdq7d69mzZrVB2UBAIChJKjA8tvf/lazZs3SPffco8rKSl1xxRVasmSJHnzwQUnSiRMnVFdXp9zcXP9jXC6XsrKyVFVVpfz8fNXU1Mjn8wXMSU5OVnp6uqqqqroMLF6vV16v13+7qalJkuTz+eTz+YKruI+c32+o9h9q4V6/NHh64Iow/bftYSbgz3Dz7fptPw76y2B5HvSXcK9fCq4HvemTwxjT7TNNdHS0JGnZsmW655579M4776igoEDPP/+87rvvPlVVVWn69On69NNPlZyc7H/cj3/8Y508eVJ79uxRaWmpHnjggYAAIkm5ublKTU3V888/32m/Ho9HhYWFncZLS0sVExPT7WIBAEDotLS0aP78+WpsbFRcXFxQjw3qCktHR4cmTZqkoqIiSdLEiRN19OhRPffcc7rvvvv88xwOR8DjjDGdxi50qTmrV6/WsmXL/LebmpqUkpKi3NzcoAvuKz6fTxUVFcrJyZHT6QzJGkIp3OuXBk8P0j17+m3brmFGj0/q0GMHh8nbcenn+FD07fpr/s/toV5OSAyW50F/Cff6peB6cP4nJD0RVGBJSkrSddddFzD2t3/7t3rllVckSW63W5JUV1enpKQk/5z6+nolJib657S1tamhoUEjR44MmDNt2rQu9+tyueRyuTqNO53OkB8gNqwhlMK9fsn+Hnjb+z9IeDscA7IfW3k7HFYfAwPB9udBfwv3+qXu9aA3PQrqXULTp0/X8ePHA8Y+/PBDjRs3TpKUmpoqt9utiooK//1tbW2qrKz0h5HMzEw5nc6AObW1tTpy5MhFAwsAAAhvQV1h+clPfqJp06apqKhI8+bN0zvvvKPNmzdr8+bNkr75UVBBQYGKioqUlpamtLQ0FRUVKSYmRvPnz5ckxcfHa/HixVq+fLlGjRqlhIQErVixQhkZGf53DQEAAHxbUIHl5ptvVllZmVavXq2f//znSk1N1caNG7VgwQL/nJUrV6q1tVVLlixRQ0ODJk+erPLycsXGxvrnbNiwQZGRkZo3b55aW1s1c+ZMbd26VREREX1XGQAAGDKCCiySlJeXp7y8vIve73A45PF45PF4LjonOjpaxcXFKi4uDnb3AAAgDPFZQgAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArBf0u4QAAJ2NX7Ur1Evokb88eUeolwB0C1dYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1ggosHo9HDocj4MvtdvvvN8bI4/EoOTlZw4cP14wZM3T06NGAbXi9Xi1dulSjR4/WiBEjNGfOHJ0+fbpvqgEAAENS0FdYrr/+etXW1vq/3nvvPf9969at0/r167Vp0yZVV1fL7XYrJydHzc3N/jkFBQUqKyvTzp07tX//fp07d055eXlqb2/vm4oAAMCQExn0AyIjA66qnGeM0caNG7VmzRrNnTtXkrRt2zYlJiaqtLRU+fn5amxsVElJibZv367s7GxJ0o4dO5SSkqK9e/dq1qxZvSwHABCM8at29erxrgijdbdI6Z498rY7+mhVl/aXJ+8YkP3ALkEHlo8++kjJyclyuVyaPHmyioqKdNVVV+nEiROqq6tTbm6uf67L5VJWVpaqqqqUn5+vmpoa+Xy+gDnJyclKT09XVVXVRQOL1+uV1+v1325qapIk+Xw++Xy+YEvoE+f3G6r9h1q41y8Nnh64Ikz/bXuYCfgz3IR7/VJoemDTc26wnAf6UzA96E2fHMaYbh9lr732mlpaWnTNNdfo888/1xNPPKEPPvhAR48e1fHjxzV9+nR9+umnSk5O9j/mxz/+sU6ePKk9e/aotLRUDzzwQED4kKTc3Fylpqbq+eef73K/Ho9HhYWFncZLS0sVExPT3eUDAIAQamlp0fz589XY2Ki4uLigHhvUFZbZs2f7/56RkaGpU6fq6quv1rZt2zRlyhRJksMReEnQGNNp7ELfNWf16tVatmyZ/3ZTU5NSUlKUm5sbdMF9xefzqaKiQjk5OXI6nSFZQyiFe/3S4OlBumdPv23bNczo8UkdeuzgMHk7BubHATYJ9/ql0PTgiMeelw8MlvNAfwqmB+d/QtITQf9I6NtGjBihjIwMffTRR7r77rslSXV1dUpKSvLPqa+vV2JioiTJ7Xarra1NDQ0NGjlyZMCcadOmXXQ/LpdLLper07jT6Qz5AWLDGkIp3OuX7O/BQLyuwNvhGLDXL9go3OuXBrYHNj7fbD8PDITu9KA3PerV72Hxer16//33lZSUpNTUVLndblVUVPjvb2trU2VlpT+MZGZmyul0Bsypra3VkSNHLhlYAABAeAvqCsuKFSt055136sorr1R9fb2eeOIJNTU1adGiRXI4HCooKFBRUZHS0tKUlpamoqIixcTEaP78+ZKk+Ph4LV68WMuXL9eoUaOUkJCgFStWKCMjw/+uIQAAgAsFFVhOnz6tf/zHf9QXX3yhyy+/XFOmTNHbb7+tcePGSZJWrlyp1tZWLVmyRA0NDZo8ebLKy8sVGxvr38aGDRsUGRmpefPmqbW1VTNnztTWrVsVERHRt5UBAIAhI6jAsnPnzkve73A45PF45PF4LjonOjpaxcXFKi4uDmbXAAAgjPFZQgAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADr9SqwrF27Vg6HQwUFBf4xY4w8Ho+Sk5M1fPhwzZgxQ0ePHg14nNfr1dKlSzV69GiNGDFCc+bM0enTp3uzFAAAMIT1OLBUV1dr8+bNuuGGGwLG161bp/Xr12vTpk2qrq6W2+1WTk6Ompub/XMKCgpUVlamnTt3av/+/Tp37pzy8vLU3t7e80oAAMCQ1aPAcu7cOS1YsEAvvPCCRo4c6R83xmjjxo1as2aN5s6dq/T0dG3btk0tLS0qLS2VJDU2NqqkpERPP/20srOzNXHiRO3YsUPvvfee9u7d2zdVAQCAISWyJw96+OGHdccddyg7O1tPPPGEf/zEiROqq6tTbm6uf8zlcikrK0tVVVXKz89XTU2NfD5fwJzk5GSlp6erqqpKs2bN6rQ/r9crr9frv93U1CRJ8vl88vl8PSmh187vN1T7D7Vwr18aPD1wRZj+2/YwE/BnuAn3+qXQ9MCm59xgOQ/0p2B60Js+BR1Ydu7cqXfffVfV1dWd7qurq5MkJSYmBownJibq5MmT/jlRUVEBV2bOzzn/+AutXbtWhYWFncbLy8sVExMTbAl9qqKiIqT7D7Vwr1+yvwfrbun/fTw+qaP/d2KxcK9fGtge7N69e8D21V22nwcGQnd60NLS0uPtBxVYTp06pUcffVTl5eWKjo6+6DyHwxFw2xjTaexCl5qzevVqLVu2zH+7qalJKSkpys3NVVxcXBAV9B2fz6eKigrl5OTI6XSGZA2hFO71S4OnB+mePf22bdcwo8cndeixg8Pk7bj0c3woCvf6pdD04Iin85X4UBks54H+FEwPzv+EpCeCCiw1NTWqr69XZmamf6y9vV1vvvmmNm3apOPHj0v65ipKUlKSf059fb3/qovb7VZbW5saGhoCrrLU19dr2rRpXe7X5XLJ5XJ1Gnc6nSE/QGxYQyiFe/2S/T3wtvf/NxFvh2NA9mOrcK9fGtge2Ph8s/08MBC604Pe9CioF93OnDlT7733ng4fPuz/mjRpkhYsWKDDhw/rqquuktvtDrgs1NbWpsrKSn8YyczMlNPpDJhTW1urI0eOXDSwAACA8BbUFZbY2Filp6cHjI0YMUKjRo3yjxcUFKioqEhpaWlKS0tTUVGRYmJiNH/+fElSfHy8Fi9erOXLl2vUqFFKSEjQihUrlJGRoezs7D4qCwAADCU9epfQpaxcuVKtra1asmSJGhoaNHnyZJWXlys2NtY/Z8OGDYqMjNS8efPU2tqqmTNnauvWrYqIiOjr5QAAgCGg14Fl3759AbcdDoc8Ho88Hs9FHxMdHa3i4mIVFxf3dvcAACAM8FlCAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgvchQLwAAgGCMX7Ur1Evwc0UYrbtFSvfskbfdcdF5f3nyjgFc1dDEFRYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArBdUYHnuued0ww03KC4uTnFxcZo6dapee+01//3GGHk8HiUnJ2v48OGaMWOGjh49GrANr9erpUuXavTo0RoxYoTmzJmj06dP9001AABgSAoqsIwdO1ZPPvmkDh48qIMHD+q2227TXXfd5Q8l69at0/r167Vp0yZVV1fL7XYrJydHzc3N/m0UFBSorKxMO3fu1P79+3Xu3Dnl5eWpvb29bysDAABDRlCB5c4779Q//MM/6JprrtE111yjf/u3f9P3vvc9vf322zLGaOPGjVqzZo3mzp2r9PR0bdu2TS0tLSotLZUkNTY2qqSkRE8//bSys7M1ceJE7dixQ++995727t3bLwUCAIDBL7KnD2xvb9fLL7+sL7/8UlOnTtWJEydUV1en3Nxc/xyXy6WsrCxVVVUpPz9fNTU18vl8AXOSk5OVnp6uqqoqzZo1q8t9eb1eeb1e/+2mpiZJks/nk8/n62kJvXJ+v6Haf6iFe/3S4OmBK8L037aHmYA/w0241y/Rg+7Wb/t5ojeCORf2pg9BB5b33ntPU6dO1VdffaXvfe97Kisr03XXXaeqqipJUmJiYsD8xMREnTx5UpJUV1enqKgojRw5stOcurq6i+5z7dq1Kiws7DReXl6umJiYYEvoUxUVFSHdf6iFe/2S/T1Yd0v/7+PxSR39vxOLhXv9Ej34rvp37949QCsJne6cC1taWnq8/aADy7XXXqvDhw/r7NmzeuWVV7Ro0SJVVlb673c4HAHzjTGdxi70XXNWr16tZcuW+W83NTUpJSVFubm5iouLC7aEPuHz+VRRUaGcnBw5nc6QrCGUwr1+afD0IN2zp9+27Rpm9PikDj12cJi8HZd+ng9F4V6/RA+6W/8RT9c/QRgKgjkXnv8JSU8EHViioqL0N3/zN5KkSZMmqbq6Wr/85S/105/+VNI3V1GSkpL88+vr6/1XXdxut9ra2tTQ0BBwlaW+vl7Tpk276D5dLpdcLlencafTGfJvFDasIZTCvX7J/h542/v/m4i3wzEg+7FVuNcv0YPvqt/mc0Rf6c65sDd96PXvYTHGyOv1KjU1VW63O+CSUFtbmyorK/1hJDMzU06nM2BObW2tjhw5csnAAgAAwltQV1j+9V//VbNnz1ZKSoqam5u1c+dO7du3T6+//rocDocKCgpUVFSktLQ0paWlqaioSDExMZo/f74kKT4+XosXL9by5cs1atQoJSQkaMWKFcrIyFB2dna/FAgAAAa/oALL559/roULF6q2tlbx8fG64YYb9PrrrysnJ0eStHLlSrW2tmrJkiVqaGjQ5MmTVV5ertjYWP82NmzYoMjISM2bN0+tra2aOXOmtm7dqoiIiL6tDAAADBlBBZaSkpJL3u9wOOTxeOTxeC46Jzo6WsXFxSouLg5m1wAAIIzxWUIAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6wUVWNauXaubb75ZsbGxGjNmjO6++24dP348YI4xRh6PR8nJyRo+fLhmzJiho0ePBszxer1aunSpRo8erREjRmjOnDk6ffp076sBAABDUlCBpbKyUg8//LDefvttVVRU6Ouvv1Zubq6+/PJL/5x169Zp/fr12rRpk6qrq+V2u5WTk6Pm5mb/nIKCApWVlWnnzp3av3+/zp07p7y8PLW3t/ddZQAAYMiIDGby66+/HnB7y5YtGjNmjGpqanTrrbfKGKONGzdqzZo1mjt3riRp27ZtSkxMVGlpqfLz89XY2KiSkhJt375d2dnZkqQdO3YoJSVFe/fu1axZs/qoNAAAMFQEFVgu1NjYKElKSEiQJJ04cUJ1dXXKzc31z3G5XMrKylJVVZXy8/NVU1Mjn88XMCc5OVnp6emqqqrqMrB4vV55vV7/7aamJkmSz+eTz+frTQk9dn6/odp/qIV7/dLg6YErwvTftoeZgD/DTbjXL9GD7tZv+3miN4I5F/amDz0OLMYYLVu2TN///veVnp4uSaqrq5MkJSYmBsxNTEzUyZMn/XOioqI0cuTITnPOP/5Ca9euVWFhYafx8vJyxcTE9LSEPlFRURHS/YdauNcv2d+Ddbf0/z4en9TR/zuxWLjXL9GD76p/9+7dA7SS0OnOubClpaXH2+9xYHnkkUf0xz/+Ufv37+90n8PhCLhtjOk0dqFLzVm9erWWLVvmv93U1KSUlBTl5uYqLi6uB6vvPZ/Pp4qKCuXk5MjpdIZkDaEU7vVLg6cH6Z49/bZt1zCjxyd16LGDw+TtuPRzfCgK9/oletDd+o94hu7LHYI5F57/CUlP9CiwLF26VL/97W/15ptvauzYsf5xt9st6ZurKElJSf7x+vp6/1UXt9uttrY2NTQ0BFxlqa+v17Rp07rcn8vlksvl6jTudDpD/o3ChjWEUrjXL9nfA297/38T8XY4BmQ/tgr3+iV68F3123yO6CvdORf2pg9BvUvIGKNHHnlEr776qn73u98pNTU14P7U1FS53e6Ay0JtbW2qrKz0h5HMzEw5nc6AObW1tTpy5MhFAwsAAAhvQV1hefjhh1VaWqrf/OY3io2N9b/mJD4+XsOHD5fD4VBBQYGKioqUlpamtLQ0FRUVKSYmRvPnz/fPXbx4sZYvX65Ro0YpISFBK1asUEZGhv9dQwAAAN8WVGB57rnnJEkzZswIGN+yZYvuv/9+SdLKlSvV2tqqJUuWqKGhQZMnT1Z5ebliY2P98zds2KDIyEjNmzdPra2tmjlzprZu3aqIiIjeVQMAAIakoAKLMd/9tjWHwyGPxyOPx3PROdHR0SouLlZxcXEwuwcAAGGKzxICAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwXmSoFwAAwFA3ftWuUC8haH958o5QLyEAV1gAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA60UG+4A333xTv/jFL1RTU6Pa2lqVlZXp7rvv9t9vjFFhYaE2b96shoYGTZ48Wc8884yuv/56/xyv16sVK1boV7/6lVpbWzVz5kw9++yzGjt2bJ8UBfSX8at2+f/uijBad4uU7tkjb7sjhKsCgKEv6CssX375pW688UZt2rSpy/vXrVun9evXa9OmTaqurpbb7VZOTo6am5v9cwoKClRWVqadO3dq//79OnfunPLy8tTe3t7zSgAAwJAV9BWW2bNna/bs2V3eZ4zRxo0btWbNGs2dO1eStG3bNiUmJqq0tFT5+flqbGxUSUmJtm/fruzsbEnSjh07lJKSor1792rWrFm9KAcAAAxFQQeWSzlx4oTq6uqUm5vrH3O5XMrKylJVVZXy8/NVU1Mjn88XMCc5OVnp6emqqqrqMrB4vV55vV7/7aamJkmSz+eTz+fryxK67fx+Q7X/UAvX+l0R5v//fZgJ+DMchXsPwr1+iR4M5fq7e34P5vtBb75n9GlgqaurkyQlJiYGjCcmJurkyZP+OVFRURo5cmSnOecff6G1a9eqsLCw03h5ebliYmL6Yuk9VlFREdL9h1q41b/uls5jj0/qGPiFWCbcexDu9Uv0YCjWv3v37qDmd+f7QUtLS0+X07eB5TyHI/AFiMaYTmMXutSc1atXa9myZf7bTU1NSklJUW5uruLi4nq/4B7w+XyqqKhQTk6OnE5nSNYQSuFaf7pnj//vrmFGj0/q0GMHh8nbEZ4vug33HoR7/RI9GMr1H/F07yUawXw/OP8Tkp7o08DidrslfXMVJSkpyT9eX1/vv+ridrvV1tamhoaGgKss9fX1mjZtWpfbdblccrlcncadTmfIv1nasIZQCrf6u3o3kLfDEfbvEgr3HoR7/RI9GIr1B3tu7873g958v+jT38OSmpoqt9sdcFmora1NlZWV/jCSmZkpp9MZMKe2tlZHjhy5aGABAADhLegrLOfOndPHH3/sv33ixAkdPnxYCQkJuvLKK1VQUKCioiKlpaUpLS1NRUVFiomJ0fz58yVJ8fHxWrx4sZYvX65Ro0YpISFBK1asUEZGhv9dQwAAAN8WdGA5ePCgfvCDH/hvn39tyaJFi7R161atXLlSra2tWrJkif8Xx5WXlys2Ntb/mA0bNigyMlLz5s3z/+K4rVu3KiIiog9KAgAAQ03QgWXGjBky5uJv33I4HPJ4PPJ4PBedEx0dreLiYhUXFwe7ewAAEIb4LCEAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHqRoV4Awtf4VbtCvQQAwCDBFRYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOuFNLA8++yzSk1NVXR0tDIzM/XWW2+FcjkAAMBSIQssL730kgoKCrRmzRodOnRIf//3f6/Zs2frk08+CdWSAACApUL2i+PWr1+vxYsX65//+Z8lSRs3btSePXv03HPPae3ataFa1qA10L+EzRVhtO4WKd2zR952x4DuGwAQfkISWNra2lRTU6NVq1YFjOfm5qqqqqrTfK/XK6/X67/d2NgoSfrrX/8qn8/Xv4u9CJ/Pp5aWFp05c0ZOpzMka/i2yK+/HNj9dRi1tHQo0jdM7R3hGVjoAT0I9/olejCU6z9z5ky35gXz/bC5uVmSZIwJej0hCSxffPGF2tvblZiYGDCemJiourq6TvPXrl2rwsLCTuOpqan9tkZ8t/mhXoAF6AE9CPf6JXowVOsf/XT/bbu5uVnx8fFBPSaknyXkcASmUWNMpzFJWr16tZYtW+a/3dHRob/+9a8aNWpUl/MHQlNTk1JSUnTq1CnFxcWFZA2hFO71S/RAogfhXr9ED8K9fim4Hhhj1NzcrOTk5KD3E5LAMnr0aEVERHS6mlJfX9/pqoskuVwuuVyugLHLLrusP5fYbXFxcWF7kErUL9EDiR6Ee/0SPQj3+qXu9yDYKyvnheRdQlFRUcrMzFRFRUXAeEVFhaZNmxaKJQEAAIuF7EdCy5Yt08KFCzVp0iRNnTpVmzdv1ieffKKHHnooVEsCAACWCllg+eEPf6gzZ87o5z//uWpra5Wenq7du3dr3LhxoVpSUFwul372s591+lFVuAj3+iV6INGDcK9fogfhXr80cD1wmJ68twgAAGAA8VlCAADAegQWAABgPQILAACwHoEFAABYj8ByEQ0NDVq4cKHi4+MVHx+vhQsX6uzZs5d8jMPh6PLrF7/4hX/OjBkzOt1/77339nM1PdOTHtx///2d6psyZUrAHK/Xq6VLl2r06NEaMWKE5syZo9OnT/djJT0TbP0+n08//elPlZGRoREjRig5OVn33XefPvvss4B5Nh8Dzz77rFJTUxUdHa3MzEy99dZbl5xfWVmpzMxMRUdH66qrrtJ//ud/dprzyiuv6LrrrpPL5dJ1112nsrKy/lp+rwVT/6uvvqqcnBxdfvnliouL09SpU7Vnz56AOVu3bu3ynPDVV1/1dyk9FkwP9u3b12V9H3zwQcC8wXQMSMH1oKtznsPh0PXXX++fM5iOgzfffFN33nmnkpOT5XA49Otf//o7HzNg5wGDLt1+++0mPT3dVFVVmaqqKpOenm7y8vIu+Zja2tqArxdffNE4HA7zpz/9yT8nKyvLPPjggwHzzp4929/l9EhPerBo0SJz++23B9R35syZgDkPPfSQueKKK0xFRYV59913zQ9+8ANz4403mq+//ro/ywlasPWfPXvWZGdnm5deesl88MEH5sCBA2by5MkmMzMzYJ6tx8DOnTuN0+k0L7zwgjl27Jh59NFHzYgRI8zJkye7nP/nP//ZxMTEmEcffdQcO3bMvPDCC8bpdJr//u//9s+pqqoyERERpqioyLz//vumqKjIREZGmrfffnugyuq2YOt/9NFHzVNPPWXeeecd8+GHH5rVq1cbp9Np3n33Xf+cLVu2mLi4uE7nBlsF24M33njDSDLHjx8PqO/bz+XBdAwYE3wPzp49G1D7qVOnTEJCgvnZz37mnzOYjoPdu3ebNWvWmFdeecVIMmVlZZecP5DnAQJLF44dO2YkBTTzwIEDRpL54IMPur2du+66y9x2220BY1lZWebRRx/tq6X2m572YNGiReauu+666P1nz541TqfT7Ny50z/26aefmmHDhpnXX3+9T9beF/rqGHjnnXeMpICTna3HwC233GIeeuihgLEJEyaYVatWdTl/5cqVZsKECQFj+fn5ZsqUKf7b8+bNM7fffnvAnFmzZpl77723j1bdd4KtvyvXXXedKSws9N/esmWLiY+P76sl9rtge3A+sDQ0NFx0m4PpGDCm98dBWVmZcTgc5i9/+Yt/bLAdB+d1J7AM5HmAHwl14cCBA4qPj9fkyZP9Y1OmTFF8fLyqqqq6tY3PP/9cu3bt0uLFizvd91//9V8aPXq0rr/+eq1YscL/cds26U0P9u3bpzFjxuiaa67Rgw8+qPr6ev99NTU18vl8ys3N9Y8lJycrPT29270dCH1xDEhSY2OjHA5Hp8++su0YaGtrU01NTcC/iyTl5uZetN4DBw50mj9r1iwdPHhQPp/vknNs+reWelb/hTo6OtTc3KyEhISA8XPnzmncuHEaO3as8vLydOjQoT5bd1/qTQ8mTpyopKQkzZw5U2+88UbAfYPlGJD65jgoKSlRdnZ2p1+COliOg2AN5HkgpJ/WbKu6ujqNGTOm0/iYMWM6fWDjxWzbtk2xsbGaO3duwPiCBQuUmpoqt9utI0eOaPXq1frDH/7Q6XOVQq2nPZg9e7buuecejRs3TidOnNBjjz2m2267TTU1NXK5XKqrq1NUVJRGjhwZ8LjExMRu93Yg9MUx8NVXX2nVqlWaP39+wAeC2XgMfPHFF2pvb+/04aOX+nepq6vrcv7XX3+tL774QklJSRedY9O/tdSz+i/09NNP68svv9S8efP8YxMmTNDWrVuVkZGhpqYm/fKXv9T06dP1hz/8QWlpaX1aQ2/1pAdJSUnavHmzMjMz5fV6tX37ds2cOVP79u3TrbfeKunix4ltx4DU++OgtrZWr732mkpLSwPGB9NxEKyBPA+EVWDxeDwqLCy85Jzq6mpJ37yA9kLGmC7Hu/Liiy9qwYIFio6ODhh/8MEH/X9PT09XWlqaJk2apHfffVc33XRTt7bdG/3dgx/+8If+v6enp2vSpEkaN26cdu3a1Sm8BbPdvjJQx4DP59O9996rjo4OPfvsswH3hfoYuJQLa/uueruaf+F4sNsMpZ6u9Ve/+pU8Ho9+85vfBATdKVOmBLzofPr06brppptUXFys//iP/+i7hfehYHpw7bXX6tprr/Xfnjp1qk6dOqV///d/9weWYLdpg56ud+vWrbrssst09913B4wPxuMgGAN1HgirwPLII49857sxxo8frz/+8Y/6/PPPO933v//7v51SYlfeeustHT9+XC+99NJ3zr3pppvkdDr10UcfDcg3q4HqwXlJSUkaN26cPvroI0mS2+1WW1ubGhoaAq6y1NfXD8gndQ9E/T6fT/PmzdOJEyf0u9/97js/bn2gj4GujB49WhEREZ3+x1NfX3/Ret1ud5fzIyMjNWrUqEvOCeYYGgg9qf+8l156SYsXL9bLL7+s7OzsS84dNmyYbr75Zv/zwSa96cG3TZkyRTt27PDfHizHgNS7Hhhj9OKLL2rhwoWKioq65Fybj4NgDeR5IKxewzJ69GhNmDDhkl/R0dGaOnWqGhsb9c477/gf+/vf/16NjY3d+qZaUlKizMxM3Xjjjd859+jRo/L5fEpKSupVbd01UD0478yZMzp16pS/vszMTDmdzoAff9TW1urIkSMDElj6u/7zYeWjjz7S3r17/U/YSxnoY6ArUVFRyszM7PRjqYqKiovWO3Xq1E7zy8vLNWnSJDmdzkvOGYh/62D0pH7pmysr999/v0pLS3XHHXd8536MMTp8+HBI/60vpqc9uNChQ4cC6hssx4DUux5UVlbq448/7vJ1ixey+TgI1oCeB4J6iW4Yuf32280NN9xgDhw4YA4cOGAyMjI6vaX12muvNa+++mrAWGNjo4mJiTHPPfdcp21+/PHHprCw0FRXV5sTJ06YXbt2mQkTJpiJEyda95ZeY4LvQXNzs1m+fLmpqqoyJ06cMG+88YaZOnWqueKKK0xTU5P/MQ899JAZO3as2bt3r3n33XfNbbfdZu3bmoOp3+fzmTlz5pixY8eaw4cPB7x90ev1GmPsPgbOv52zpKTEHDt2zBQUFJgRI0b43+2watUqs3DhQv/8829n/MlPfmKOHTtmSkpKOr2d8X/+539MRESEefLJJ837779vnnzySWvf0hps/aWlpSYyMtI888wzF32LusfjMa+//rr505/+ZA4dOmQeeOABExkZaX7/+98PeH3dEWwPNmzYYMrKysyHH35ojhw5YlatWmUkmVdeecU/ZzAdA8YE34PzfvSjH5nJkyd3uc3BdBw0NzebQ4cOmUOHDhlJZv369ebQoUP+dzqG8jxAYLmIM2fOmAULFpjY2FgTGxtrFixY0Omte5LMli1bAsaef/55M3z48C5/r8Ynn3xibr31VpOQkGCioqLM1Vdfbf7lX/6l0+8psUWwPWhpaTG5ubnm8ssvN06n01x55ZVm0aJF5pNPPgl4TGtrq3nkkUdMQkKCGT58uMnLy+s0xwbB1n/ixAkjqcuvN954wxhj/zHwzDPPmHHjxpmoqChz0003mcrKSv99ixYtMllZWQHz9+3bZyZOnGiioqLM+PHjuwzqL7/8srn22muN0+k0EyZMCPhmZptg6s/Kyury33rRokX+OQUFBebKK680UVFR5vLLLze5ubmmqqpqACsKXjA9eOqpp8zVV19toqOjzciRI833v/99s2vXrk7bHEzHgDHBPw/Onj1rhg8fbjZv3tzl9gbTcXD+reoXO65DeR5wGPP/Xh0DAABgqbB6DQsAABicCCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsN7/BRgzS8CRrcLOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(ITE_pred_fact).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16414f33-1f8c-49fe-8da9-f889b4eabf27",
   "metadata": {},
   "source": [
    "# Training a PEACE model with all our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077104c5-3a1b-411b-b109-368fa8d7748f",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a1adf3-3043-413f-b8ba-d4884bd58b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frenk_sent_train = np.load('outs/frenk/sent_train_outs.npy')\n",
    "frenk_gen_train = np.load('outs/frenk/gen_train_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d55605-2b74-4b41-a95f-4c34266cf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_sent_train = np.load('outs/try/sent_train_outs.npy')\n",
    "try_gen_train = np.load('outs/try/gen_train_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51266a6d-0f4f-49b2-abbe-f8f733806a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sent = np.load('outs/counterfactuals/sent_fact_outs.npy')\n",
    "fact_gen = np.load('outs/counterfactuals/gen_fact_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "501e61df-35d7-41bc-877e-136837f0fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train = np.concatenate([frenk_sent_train,try_sent_train,fact_sent],axis=0)\n",
    "gen_train = np.concatenate([frenk_gen_train,try_gen_train,fact_gen],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d5d826f-fd4b-4836-8506-59caa3d721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_train = np.concatenate([sent_train,gen_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a0f74-5c0e-41b1-a2b3-acb54c7c420f",
   "metadata": {},
   "source": [
    "## Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b1b8fe-2f42-4457-8db3-8fcbf857072f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "98e5e4c1ef214179bcd5a6e6f3b9632d",
      "482795395a764b0b8ac6167c358c2bf8",
      "d4bb70f128f64cdd9339e4f3cb83f3b4",
      "7570723a96df45679a13d7c438d466e5",
      "6b2d2176afd643c796985f1353f36323",
      "d247e2738a5e423cb06dd55693d449d0",
      "4491981ccfec475abca58b9abe17e276",
      "99a31e2a373f4a1fa93a2bf9f01edbf1",
      "748e0715760d4d15b208c0aeb2b04356",
      "f5d04592b62d4a6e97e25ba5e9a32326",
      "a91f49931eea4d92b6c1d2b20c4aefcf",
      "7a64ed0166b945a2ae0ddb9ff89bbd56",
      "a51747d13e7b465581f777211ec9549b",
      "f4b74ca0fa154f43b9f789ab34852d4e",
      "b4c3c15330494d79ab5b4e8c6551a3fe",
      "036ad7eb94674978b468a920b137909f",
      "52f2023f766144c493c01cb4d5584bea",
      "17f1c3680b77467787907339c85483a2",
      "197cc63ffeb0453fba7730a9b8bd531d",
      "536d0694580e46ad9356586aea88627d",
      "e5b7fe1e3cf544a093c3bbc1f075545a",
      "c1e07d59106544bdbd0cde97380c88db",
      "f272ebd214f143579a747d37f06f8578",
      "3b76aca2cab644f4adb0a9c24b33865d",
      "4f658c94ca774adeb6c27f0b8d68b368",
      "f8d2fab6726a49e8b8443783f5f20911",
      "4f240765e11f47e5b8110c3cb2f81b35",
      "a4029f83f1294ca981a62817ac835484",
      "81c392bd546145eabd2bd1ff0b246911",
      "4d7af20dd05f494fa1dd92ae73fe158b",
      "5933c72a748b4db58078f517db5c5120",
      "8e33c271de1744bc8d0b6f67c1101dcc",
      "a6ce855654cc4ca295ce3689984ac226",
      "9ea59faa0bd9499f8c7cca5daf9b76e6",
      "29c4fec6dab24c939932e910db29f9ff",
      "c735bcf28dde4305a1642a2bdbf3dfcb",
      "f5970bf0a69842e692041a7a2c21dfb1",
      "5e1988dc726b441ebc1d264a98b83fbc",
      "ad9364544e214b8483520020a3b87df2",
      "701e0f2fbad3463b9c66e8a7e4949144",
      "2a314420428a4ce68ee073a113a1865e",
      "cb1f8f1990674960b54a418a6b943bf4",
      "e87b2bd9a2ed42759ef716c07a882ad5",
      "3ded0e0a04d848288c4e07fb2ccb0b18",
      "729406de6279478cac75ccb416ce32e3",
      "7333fc5f3900426bb7d7434e5eb022eb",
      "0c1bf462bbd546b79fde5184783b20ca",
      "fc2a3ed815b547509babfe56b6b0028c",
      "012301170183417b8ef37fc3be9a83a5",
      "35f31858d8874821bcaa11016848b20a",
      "982671eca74a4ca0b2d088547299cc8f",
      "2b632fea606d45159af0119fa75608e9",
      "aae8849e337343f3af0ecf16e3af771c",
      "4d35111788134cb39ed708ac586b83eb",
      "73db15a993774ae1bda701fe24873603",
      "144c0ffba3594009a8aa65b559c0b952",
      "3e9439cf81a945189375acb8c4b1cc17",
      "54d65145ad394f2c87a90e261677f32b",
      "7b621ddc28824e0a9f44e5ed8b07929d",
      "cc1490fef2964807b77fbdda5976e7a8",
      "ca55578fb1e34028af4b62f202f0c052",
      "03fb007c6c0449c2944e714a0a0bb9e5",
      "a0d76c86d1134f1499635b9ac8060808",
      "734d37cfc6cf470da494439db51cd41f",
      "ebf45b42aa1a48a69981ed743e1ffd4c",
      "fbb555562628439a8688074da28c6cd6"
     ]
    },
    "id": "XLUg9YO7w9eC",
    "outputId": "3058b858-8eb3-44fc-da98-7cccb19cd65e"
   },
   "outputs": [],
   "source": [
    "#FRENK dataset\n",
    "df_train = pd.read_csv('data/frenk_train.tsv',sep='\\t')\n",
    "frenk_label_train = df_train[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dd39afb-12fa-4242-b91d-9f1de6b36bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twi-Red-You dataset\n",
    "df_train = pd.read_csv('data/try_train.tsv',sep='\\t')\n",
    "try_label_train = df_train['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89230f50-52a8-4be9-9bfa-387005961218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factuals\n",
    "df_factuals = pd.read_csv('data/factuals.tsv',sep='\\t')\n",
    "labels_factuals = df_factuals[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e3bfeb4-f7b8-44ef-bbfd-32e39f0c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.concatenate([frenk_label_train,try_label_train,labels_factuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "011266dd-b088-4e38-bc9f-1cef43cd8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights = compute_class_weight('balanced', classes=np.unique(label_train), y=label_train)\n",
    "c_weights = {0:c_weights[0], 1:c_weights[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a966b3-4b2f-43b8-a21a-85a8a19a7f12",
   "metadata": {},
   "source": [
    "## Training and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6550b52-7e78-456b-b62d-73f061f7fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_train,conc_val,label_train,label_val = train_test_split(conc_train,label_train,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330df37-4a91-4ee7-a30a-ccd76c9daae5",
   "metadata": {},
   "source": [
    "## Training the PEACE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3722973-b535-4d57-b1d0-5054c27d84ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5505 - accuracy: 0.7072\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5174 - accuracy: 0.7263\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5028 - accuracy: 0.7370\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4931 - accuracy: 0.7380\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4799 - accuracy: 0.7462\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4675 - accuracy: 0.7549\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4589 - accuracy: 0.7541\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.4429 - accuracy: 0.7657\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4313 - accuracy: 0.7726\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4173 - accuracy: 0.7786\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7099\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5233 - accuracy: 0.7213\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5070 - accuracy: 0.7326\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4940 - accuracy: 0.7402\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4840 - accuracy: 0.7434\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.7547\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4572 - accuracy: 0.7563\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4428 - accuracy: 0.7699\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4309 - accuracy: 0.7744\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4156 - accuracy: 0.7823\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5486 - accuracy: 0.7029\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5173 - accuracy: 0.7263\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5039 - accuracy: 0.7319\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 3s 4ms/step - loss: 0.4928 - accuracy: 0.7374\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4810 - accuracy: 0.7464\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4752 - accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4586 - accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.7652\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4345 - accuracy: 0.7722\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4171 - accuracy: 0.7816\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7072\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.5159 - accuracy: 0.7270\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.5037 - accuracy: 0.7317\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4930 - accuracy: 0.7378\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4817 - accuracy: 0.7419\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.7523\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4534 - accuracy: 0.7598\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.7659\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4316 - accuracy: 0.7725\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4132 - accuracy: 0.7789\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 3s 4ms/step - loss: 0.5496 - accuracy: 0.7054\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5199 - accuracy: 0.7239\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5062 - accuracy: 0.7328\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7399\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4817 - accuracy: 0.7461\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4696 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4606 - accuracy: 0.7563\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4489 - accuracy: 0.7596\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4325 - accuracy: 0.7725\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.4217 - accuracy: 0.7812\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7053\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7233\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7350\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.7391\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7421\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7508\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7550\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7634\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4365 - accuracy: 0.7681\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.4155 - accuracy: 0.7832\n",
      "67/67 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7048\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7253\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7340\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.7382\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7421\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7478\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7535\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.7618\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.4357 - accuracy: 0.7688\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.4213 - accuracy: 0.7749\n",
      "67/67 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7097\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7258\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.7343\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.7396\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7466\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.7494\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.7572\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7651\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4354 - accuracy: 0.7675\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4216 - accuracy: 0.7813\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7081\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7249\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7342\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.7378\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7430\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7497\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.7598\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7651\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4304 - accuracy: 0.7732\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4144 - accuracy: 0.7836\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "603/603 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7043\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7251\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7331\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4944 - accuracy: 0.7391\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4816 - accuracy: 0.7483\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7550\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7593\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.7675\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4345 - accuracy: 0.7714\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4204 - accuracy: 0.7791\n",
      "67/67 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "best_f1_val = 0\n",
    "best_model = None\n",
    "for i in range(n_runs):\n",
    "    hate_model = Sequential([\n",
    "          Flatten(),\n",
    "          Dense(128, activation='relu'),\n",
    "          Dense(128, activation='relu'),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "    hate_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    hate_model.fit(conc_train, label_train, class_weight=c_weights, epochs=10, batch_size=32)\n",
    "    \n",
    "    #Selecting the model with best f1 score in the validation set\n",
    "    f_hate = np.squeeze(hate_model.predict(conc_val))\n",
    "    preds = (f_hate > 0.5).astype(int)\n",
    "    f1_val = metrics.f1_score(preds,label_val,zero_division=1)\n",
    "    if f1_val > best_f1_val:\n",
    "        best_f1_val = f1_val\n",
    "        best_model = hate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11efd5eb-c8ee-4514-b15b-589c266d1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ITE_model/models/PEACE_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save('models/ITE_model/models/PEACE_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
