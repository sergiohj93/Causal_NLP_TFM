{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0088923-9667-4588-860b-7776ca55856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification, BertModel, BertForSequenceClassification, BertTokenizer\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Concatenate, GlobalAveragePooling1D\n",
    "from keras import backend as K\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import tensorflow as tf\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ddeff-cef7-4935-950e-bdc838804930",
   "metadata": {},
   "source": [
    "# Training of the ITE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138e16f-736b-4128-805c-8875a1868bea",
   "metadata": {},
   "source": [
    "## Loading the embeddings as the inputs and the ITE as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a15ba54-4b5a-4588-987c-573067a1aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3127, 1536)\n"
     ]
    }
   ],
   "source": [
    "sent_fact_outs = np.load('outs/counterfactuals/sent_fact_outs.npy')\n",
    "gen_fact_outs = np.load('outs/counterfactuals/gen_fact_outs.npy')\n",
    "conc_fact = np.concatenate([sent_fact_outs,gen_fact_outs],axis=1)\n",
    "print(conc_fact.shape)\n",
    "\n",
    "#Copying the factuals in order to have one for each counterfactual.\n",
    "n_cf = 5\n",
    "fact_n_cf = [] \n",
    "for i in range(len(conc_fact)):\n",
    "    for j in range(n_cf):\n",
    "        fact_n_cf.append(conc_fact[i])\n",
    "fact_n_cf = np.array(fact_n_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b543b2-2f32-41b5-8e0f-cde7c0a03afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITE_peace = np.load('outs/counterfactuals/ITE_peace.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8027b-7ac4-4bea-81cd-2537440aae0c",
   "metadata": {},
   "source": [
    "## Training the model to evaluate the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553a0dd0-930e-4613-b585-df4419b04148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_keras(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bde8fbb-62b8-4863-8d4a-f953e7fb9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "        return np.mean(np.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfafbab-fe71-42e6-9980-3451933982cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avg = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0bffaf-6db8-4247-b53a-5d86c9223ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_train,fact_test,ITE_train,ITE_test = train_test_split(fact_n_cf,ITE_peace,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a13346b-fd74-4185-a47e-d2e1c51b3329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15635, 1536)\n",
      "(10944, 1536)\n",
      "(4691, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(fact_n_cf.shape)\n",
    "print(fact_train.shape)\n",
    "print(fact_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ae1ab6-c190-4563-b539-21df5f1f699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0701 - val_loss: 0.0534\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0518\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0514\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0466\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0407 - val_loss: 0.0437\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0440\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0457\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0437\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0423\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0398\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0326 - val_loss: 0.0406\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0309 - val_loss: 0.0391\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0447\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0362\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0397\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0414\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0388\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0401\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0367\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0373\n",
      "342/342 [==============================] - 0s 923us/step\n",
      "147/147 [==============================] - 0s 959us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0725 - val_loss: 0.0604\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0549 - val_loss: 0.0552\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0490 - val_loss: 0.0507\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0501\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0460\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0491\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0377 - val_loss: 0.0423\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0433\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0441\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0417\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0376\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0310 - val_loss: 0.0375\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0305 - val_loss: 0.0403\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0304 - val_loss: 0.0399\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0291 - val_loss: 0.0390\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0375\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0370\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0355\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0275 - val_loss: 0.0362\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0347\n",
      "342/342 [==============================] - 0s 906us/step\n",
      "147/147 [==============================] - 0s 972us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0780 - val_loss: 0.0568\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0535 - val_loss: 0.0613\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0494 - val_loss: 0.0528\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0435 - val_loss: 0.0484\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0414 - val_loss: 0.0458\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0388 - val_loss: 0.0456\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0439\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.0428\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0407\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0330 - val_loss: 0.0441\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0312 - val_loss: 0.0409\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0393\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0422\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.0388\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0409\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0399\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0278 - val_loss: 0.0401\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0369\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0362\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0268 - val_loss: 0.0371\n",
      "342/342 [==============================] - 0s 876us/step\n",
      "147/147 [==============================] - 0s 844us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0744 - val_loss: 0.0593\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0514\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0495\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0490\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0480\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0427\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0427\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0346 - val_loss: 0.0414\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0402\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0431\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0304 - val_loss: 0.0386\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0406\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.0398\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0295 - val_loss: 0.0381\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0375\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0282 - val_loss: 0.0365\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0284 - val_loss: 0.0350\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0395\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0275 - val_loss: 0.0402\n",
      "342/342 [==============================] - 0s 830us/step\n",
      "147/147 [==============================] - 0s 966us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0747 - val_loss: 0.0586\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0584\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0513\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0473\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0486\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0489\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0461\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0436\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0401\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0418\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0329 - val_loss: 0.0394\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0317 - val_loss: 0.0360\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0301 - val_loss: 0.0393\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0308 - val_loss: 0.0390\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0287 - val_loss: 0.0370\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0286 - val_loss: 0.0355\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0286 - val_loss: 0.0372\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0276 - val_loss: 0.0349\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0272 - val_loss: 0.0359\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0371\n",
      "342/342 [==============================] - 1s 1ms/step\n",
      "147/147 [==============================] - 0s 933us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0709 - val_loss: 0.0557\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0544 - val_loss: 0.0514\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0486 - val_loss: 0.0490\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0445 - val_loss: 0.0495\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0449\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0438\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0431\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0355 - val_loss: 0.0402\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0341 - val_loss: 0.0403\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0326 - val_loss: 0.0393\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0322 - val_loss: 0.0406\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0304 - val_loss: 0.0388\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0395\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0423\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0395\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0283 - val_loss: 0.0355\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0345\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0353\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0354\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0268 - val_loss: 0.0368\n",
      "342/342 [==============================] - 0s 930us/step\n",
      "147/147 [==============================] - 0s 974us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0750 - val_loss: 0.0563\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0534 - val_loss: 0.0506\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0584\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0448 - val_loss: 0.0526\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0427 - val_loss: 0.0460\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0393 - val_loss: 0.0453\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0367 - val_loss: 0.0446\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0458\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0328 - val_loss: 0.0430\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0327 - val_loss: 0.0400\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.0383\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0312 - val_loss: 0.0392\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0296 - val_loss: 0.0397\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0401\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0402\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0282 - val_loss: 0.0409\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0391\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0366\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0266 - val_loss: 0.0436\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0266 - val_loss: 0.0384\n",
      "342/342 [==============================] - 0s 860us/step\n",
      "147/147 [==============================] - 0s 815us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0758 - val_loss: 0.0578\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0546 - val_loss: 0.0643\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0481 - val_loss: 0.0487\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0435 - val_loss: 0.0452\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0416 - val_loss: 0.0498\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0490\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0375 - val_loss: 0.0480\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0467\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0397\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0389\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0322 - val_loss: 0.0423\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0407\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0306 - val_loss: 0.0393\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.0407\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0382\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0284 - val_loss: 0.0362\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0278 - val_loss: 0.0366\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0420\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0372\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0378\n",
      "342/342 [==============================] - 0s 886us/step\n",
      "147/147 [==============================] - 0s 913us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0783 - val_loss: 0.0539\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0521\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0484\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0506\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0457\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0464\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0422\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0418\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0408\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0432\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0314 - val_loss: 0.0393\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0416\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0390\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0285 - val_loss: 0.0370\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0364\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0385\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0279 - val_loss: 0.0387\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0405\n",
      "342/342 [==============================] - 0s 955us/step\n",
      "147/147 [==============================] - 0s 947us/step\n",
      "Epoch 1/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0746 - val_loss: 0.0557\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0548\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0468\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0467\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0418 - val_loss: 0.0483\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0491\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0444\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0484\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0467\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0444\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0419\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0395\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0305 - val_loss: 0.0391\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0392\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0289 - val_loss: 0.0395\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0282 - val_loss: 0.0392\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0395\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0405\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0369\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0269 - val_loss: 0.0378\n",
      "342/342 [==============================] - 0s 886us/step\n",
      "147/147 [==============================] - 0s 916us/step\n"
     ]
    }
   ],
   "source": [
    "ITE_pred_train = []\n",
    "ITE_pred_test = []\n",
    "for i in range(n_avg):\n",
    "    ITE_model = Sequential([\n",
    "              Flatten(),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(64, activation='relu'),\n",
    "              Dense(1, activation='tanh')\n",
    "          ])\n",
    "    ITE_model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    ITE_model.fit(fact_train,ITE_train,epochs=20,batch_size=32,validation_split=0.1)\n",
    "    ITE_pred_train.append(np.squeeze(ITE_model.predict(fact_train)))\n",
    "    ITE_pred_test.append(np.squeeze(ITE_model.predict(fact_test)))\n",
    "ITE_pred_train = np.mean(ITE_pred_train,axis=0)\n",
    "ITE_pred_test = np.mean(ITE_pred_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c24308-3489-41d0-af9b-f1ae8f0f38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.021737048\n",
      "MSE test: 0.0344448\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE train:\",mse(ITE_train,ITE_pred_train))\n",
    "print(\"MSE test:\",mse(ITE_test,ITE_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca39ea-7d87-43cd-9368-16850b277d89",
   "metadata": {},
   "source": [
    "## Training the model with all the data (train and test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f9812d-00e2-486d-b5b9-c9c22a499867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0851 - val_loss: 0.0707\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0624\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0466 - val_loss: 0.0614\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0425 - val_loss: 0.0626\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0816\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0648\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0658\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0638\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0340 - val_loss: 0.0614\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0324 - val_loss: 0.0652\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0629\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0608\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0300 - val_loss: 0.0704\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0299 - val_loss: 0.0622\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0296 - val_loss: 0.0640\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0289 - val_loss: 0.0614\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0282 - val_loss: 0.0602\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0286 - val_loss: 0.0598\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0281 - val_loss: 0.0657\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0627\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0636\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0672\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0662\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0650\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0639\n",
      "98/98 [==============================] - 0s 845us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0686 - val_loss: 0.0628\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0604\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0450 - val_loss: 0.0605\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0656\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0392 - val_loss: 0.0633\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0681\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0657\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0652\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0637\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0650\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0627\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0298 - val_loss: 0.0663\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0294 - val_loss: 0.0653\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0288 - val_loss: 0.0669\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0288 - val_loss: 0.0618\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0285 - val_loss: 0.0657\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0282 - val_loss: 0.0636\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0277 - val_loss: 0.0635\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0631\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0627\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0268 - val_loss: 0.0636\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0607\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0647\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0634\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0260 - val_loss: 0.0612\n",
      "98/98 [==============================] - 0s 928us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0702 - val_loss: 0.0618\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0521 - val_loss: 0.0563\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0462 - val_loss: 0.0570\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0419 - val_loss: 0.0578\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0657\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0645\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0565\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0600\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0597\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0613\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0596\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0300 - val_loss: 0.0565\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0296 - val_loss: 0.0626\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0295 - val_loss: 0.0604\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0294 - val_loss: 0.0576\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0286 - val_loss: 0.0599\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0592\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0278 - val_loss: 0.0605\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0630\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0647\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.0599\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0602\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0599\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0261 - val_loss: 0.0625\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0620\n",
      "98/98 [==============================] - 0s 937us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0696 - val_loss: 0.0620\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0528 - val_loss: 0.0623\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0465 - val_loss: 0.0632\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0425 - val_loss: 0.0642\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0637\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0677\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0667\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.0664\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0682\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0666\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0306 - val_loss: 0.0667\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0654\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.0704\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0298 - val_loss: 0.0642\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0284 - val_loss: 0.0614\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0283 - val_loss: 0.0692\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0282 - val_loss: 0.0681\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0655\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0666\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0704\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0669\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0638\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0268 - val_loss: 0.0659\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0648\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0608\n",
      "98/98 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 2s 3ms/step - loss: 0.0665 - val_loss: 0.0616\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0521 - val_loss: 0.0635\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0458 - val_loss: 0.0626\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0597\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0384 - val_loss: 0.0623\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0620\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0639\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0728\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0316 - val_loss: 0.0677\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0649\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0300 - val_loss: 0.0647\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0298 - val_loss: 0.0654\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0285 - val_loss: 0.0658\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0289 - val_loss: 0.0651\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0283 - val_loss: 0.0625\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0653\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0639\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0641\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0660\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0269 - val_loss: 0.0696\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0669\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0699\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0258 - val_loss: 0.0651\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0260 - val_loss: 0.0631\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0634\n",
      "98/98 [==============================] - 0s 874us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0666 - val_loss: 0.0644\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0684\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0469 - val_loss: 0.0647\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0701\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0392 - val_loss: 0.0693\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0689\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0644\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0640\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0715\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0652\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0664\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0651\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0691\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0637\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0647\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0280 - val_loss: 0.0655\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0282 - val_loss: 0.0726\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0644\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0669\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0656\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0269 - val_loss: 0.0674\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0644\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0653\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0666\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0683\n",
      "98/98 [==============================] - 0s 901us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0663 - val_loss: 0.0648\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0628\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0461 - val_loss: 0.0618\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0429 - val_loss: 0.0582\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0658\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0612\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0586\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0650\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.0613\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0590\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0639\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0587\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0590\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0295 - val_loss: 0.0595\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0602\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0593\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0280 - val_loss: 0.0606\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0283 - val_loss: 0.0605\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0573\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0277 - val_loss: 0.0605\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0593\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0589\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0268 - val_loss: 0.0600\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0629\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0601\n",
      "98/98 [==============================] - 0s 943us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0679 - val_loss: 0.0600\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0525 - val_loss: 0.0653\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0478 - val_loss: 0.0616\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0619\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0656\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0655\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0665\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0620\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0696\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0677\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0310 - val_loss: 0.0677\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0305 - val_loss: 0.0659\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.0672\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0655\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0291 - val_loss: 0.0668\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0286 - val_loss: 0.0668\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0284 - val_loss: 0.0643\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0279 - val_loss: 0.0638\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0278 - val_loss: 0.0657\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0658\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0623\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0274 - val_loss: 0.0645\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0685\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0633\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0266 - val_loss: 0.0650\n",
      "98/98 [==============================] - 0s 872us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0641\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0799\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0480 - val_loss: 0.0627\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0424 - val_loss: 0.0590\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0590\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0629\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0663\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0614\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0622\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0316 - val_loss: 0.0701\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0638\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0665\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0298 - val_loss: 0.0671\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0670\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0608\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0282 - val_loss: 0.0602\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0661\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0279 - val_loss: 0.0615\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0280 - val_loss: 0.0671\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0273 - val_loss: 0.0612\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0268 - val_loss: 0.0636\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0622\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0637\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0632\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0616\n",
      "98/98 [==============================] - 0s 682us/step\n",
      "Epoch 1/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0607\n",
      "Epoch 2/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0583\n",
      "Epoch 3/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0462 - val_loss: 0.0560\n",
      "Epoch 4/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0655\n",
      "Epoch 5/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0618\n",
      "Epoch 6/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0658\n",
      "Epoch 7/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0599\n",
      "Epoch 8/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0335 - val_loss: 0.0597\n",
      "Epoch 9/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0599\n",
      "Epoch 10/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0314 - val_loss: 0.0638\n",
      "Epoch 11/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0315 - val_loss: 0.0598\n",
      "Epoch 12/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0618\n",
      "Epoch 13/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0605\n",
      "Epoch 14/25\n",
      "440/440 [==============================] - 1s 2ms/step - loss: 0.0285 - val_loss: 0.0600\n",
      "Epoch 15/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0284 - val_loss: 0.0614\n",
      "Epoch 16/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0282 - val_loss: 0.0618\n",
      "Epoch 17/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0279 - val_loss: 0.0629\n",
      "Epoch 18/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0604\n",
      "Epoch 19/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0278 - val_loss: 0.0607\n",
      "Epoch 20/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0274 - val_loss: 0.0623\n",
      "Epoch 21/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0266 - val_loss: 0.0664\n",
      "Epoch 22/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0595\n",
      "Epoch 23/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0596\n",
      "Epoch 24/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0595\n",
      "Epoch 25/25\n",
      "440/440 [==============================] - 1s 1ms/step - loss: 0.0261 - val_loss: 0.0622\n",
      "98/98 [==============================] - 0s 872us/step\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf\n",
    "best_ITE_model = None\n",
    "ITE_pred_fact = []\n",
    "for i in range(n_avg):\n",
    "    ITE_model = Sequential([\n",
    "              Flatten(),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(64, activation='relu'),\n",
    "              Dense(1, activation='tanh')\n",
    "          ])\n",
    "    ITE_model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    history = ITE_model.fit(fact_n_cf,ITE_peace,epochs=25,batch_size=32,validation_split=0.1)\n",
    "    ITE_pred_fact.append(np.squeeze(ITE_model.predict(conc_fact)))\n",
    "    \n",
    "    # Get the last validation loss\n",
    "    last_val_loss = history.history['val_loss'][-1]\n",
    "    # Compare with the best validation loss\n",
    "    if last_val_loss < best_val_loss:\n",
    "        best_val_loss = last_val_loss\n",
    "        best_ITE_model = ITE_model\n",
    "\n",
    "ITE_pred_fact = np.mean(ITE_pred_fact,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8fa636-dc07-483c-9c5a-ae6767e2619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ITE_model/models/ITE_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_ITE_model.save('ITE_model/models/ITE_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4146d-edce-4ea1-bc08-33436664bf6e",
   "metadata": {},
   "source": [
    "## Average ITE of the factuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4b7824-15b8-45c9-908d-50f386debd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ITE: 0.29208893\n"
     ]
    }
   ],
   "source": [
    "print(\"Average ITE:\",np.mean(ITE_pred_fact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b7c897-3f5b-4821-a5d9-f2eb5d9da31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAu5ElEQVR4nO3dfXSU5Z3/8c+QTCYkJikPmkkkArqhVYOWDSUStwtbklAqUpezjV1YpJXuoQdF00AplHYdqg2aPQI2VPboYYEVaTy10nVX1Aw/a4QGK6T1lIdW3RrR1MSsGpJg4mRMrt8fOZntEMDceZi5Mnm/zpkT55rrnvt7fTNz8/GemYzLGGMEAABgkTHRLgAAAOBcBBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHXio13AQHR3d+vdd99VSkqKXC5XtMsBAAD9YIxRW1ubMjMzNWbMxc+RjMiA8u677yorKyvaZQAAgAF45513NGnSpIvOGZEBJSUlRVLPAlNTU6NczfkFg0FVVVWpqKhIbrc72uVEDX2gB73oQw/6QA96jcY+tLa2KisrK/Tv+MWMyIDS+7JOamqq1QElKSlJqampo+aBdz70gR70og896AM96DWa+9Cft2fwJlkAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA68RHuwAAw2vK+meiXYIkyRNnVD5LyvE9r0DXxb9q/a37b4pQVQBsxRkUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDqOAsqUKVPkcrn6XO644w5JkjFGPp9PmZmZGjt2rObOnauTJ0+G3UcgENDq1as1ceJEJScna9GiRaqvrx+6FQEAgBHPUUA5evSoGhoaQhe/3y9J+trXviZJKi8v15YtW7R9+3YdPXpUXq9XhYWFamtrC91HSUmJ9u/fr8rKSh0+fFhnz57VwoUL1dXVNYTLAgAAI5mjgHLppZfK6/WGLv/93/+tq666SnPmzJExRtu2bdPGjRu1ePFi5eTkaM+ePWpvb9e+ffskSS0tLdq5c6cefPBBFRQUaMaMGdq7d6+OHz+ugwcPDssCAQDAyDPg96B0dnZq7969uv322+VyuVRXV6fGxkYVFRWF5ng8Hs2ZM0c1NTWSpNraWgWDwbA5mZmZysnJCc0BAACIH+iGv/zlL3XmzBl94xvfkCQ1NjZKktLT08Pmpaen6/Tp06E5CQkJGjduXJ85vdufTyAQUCAQCF1vbW2VJAWDQQWDwYEuYVj11mVrfZFCH6LfA0+cicp+z+UZY8J+XkwsP16i/XiwAT3oMRr74GStAw4oO3fu1IIFC5SZmRk27nK5wq4bY/qMnevT5mzevFmbNm3qM15VVaWkpCQHVUde7/t0Rjv6EL0elM+Kym4v6N6Z3Z8658CBAxGoJLp4TtCDXqOpD+3t7f2eO6CAcvr0aR08eFBPPfVUaMzr9UrqOUuSkZERGm9qagqdVfF6vers7FRzc3PYWZSmpibl5+dfcH8bNmxQaWlp6Hpra6uysrJUVFSk1NTUgSxh2AWDQfn9fhUWFsrtdke7nKihD9HvQY7v+Yjv83w8Y4zundmtHx4bo0D3xf+n5YRvfoSqirxoPx5sQA96jMY+9L4C0h8DCii7du3SZZddpptuuik0NnXqVHm9Xvn9fs2YMUNSz/tUqqur9cADD0iScnNz5Xa75ff7VVxcLElqaGjQiRMnVF5efsH9eTweeTyePuNut9v6X+pIqDES6EP0ehDoungYiLRAt+tTaxoNjxWeE/Sg12jqg5N1Og4o3d3d2rVrl5YvX674+P/b3OVyqaSkRGVlZcrOzlZ2drbKysqUlJSkJUuWSJLS0tK0YsUKrVmzRhMmTND48eO1du1aTZ8+XQUFBU5LAQAAMcpxQDl48KDefvtt3X777X1uW7dunTo6OrRq1So1NzcrLy9PVVVVSklJCc3ZunWr4uPjVVxcrI6ODs2bN0+7d+9WXFzc4FYCAABihuOAUlRUJGPO/y58l8sln88nn893we0TExNVUVGhiooKp7sGMEpMWf9MtEtw7K37b/r0SQD6je/iAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdxwHlz3/+s/7pn/5JEyZMUFJSkj7/+c+rtrY2dLsxRj6fT5mZmRo7dqzmzp2rkydPht1HIBDQ6tWrNXHiRCUnJ2vRokWqr68f/GoAAEBMcBRQmpubdeONN8rtduvZZ5/VqVOn9OCDD+ozn/lMaE55ebm2bNmi7du36+jRo/J6vSosLFRbW1toTklJifbv36/KykodPnxYZ8+e1cKFC9XV1TVkCwMAACNXvJPJDzzwgLKysrRr167Q2JQpU0L/bYzRtm3btHHjRi1evFiStGfPHqWnp2vfvn1auXKlWlpatHPnTj322GMqKCiQJO3du1dZWVk6ePCg5s+fPwTLAgAAI5mjgPL0009r/vz5+trXvqbq6mpdfvnlWrVqlf75n/9ZklRXV6fGxkYVFRWFtvF4PJozZ45qamq0cuVK1dbWKhgMhs3JzMxUTk6OampqzhtQAoGAAoFA6Hpra6skKRgMKhgMOltxhPTWZWt9kUIfot8DT5yJyn7P5Rljwn7Gmv7+fqP9eLABPegxGvvgZK2OAsqbb76pHTt2qLS0VN///vf1yiuv6K677pLH49Ftt92mxsZGSVJ6enrYdunp6Tp9+rQkqbGxUQkJCRo3blyfOb3bn2vz5s3atGlTn/GqqiolJSU5WULE+f3+aJdgBfoQvR6Uz4rKbi/o3pnd0S5hWBw4cMDRfJ4T9KDXaOpDe3t7v+c6Cijd3d2aOXOmysrKJEkzZszQyZMntWPHDt12222heS6XK2w7Y0yfsXNdbM6GDRtUWloaut7a2qqsrCwVFRUpNTXVyRIiJhgMyu/3q7CwUG63O9rlRA19iH4PcnzPR3yf5+MZY3TvzG798NgYBbovfjwYiU74+vfydLQfDzagBz1GYx96XwHpD0cBJSMjQ9dcc03Y2NVXX61f/OIXkiSv1yup5yxJRkZGaE5TU1PorIrX61VnZ6eam5vDzqI0NTUpPz//vPv1eDzyeDx9xt1ut/W/1JFQYyTQh+j1INBlVxgIdLusq2koOP3d8pygB71GUx+crNPRp3huvPFGvfbaa2Fjr7/+uiZPnixJmjp1qrxeb9jpqs7OTlVXV4fCR25urtxud9ichoYGnThx4oIBBQAAjC6OzqB85zvfUX5+vsrKylRcXKxXXnlFjzzyiB555BFJPS/tlJSUqKysTNnZ2crOzlZZWZmSkpK0ZMkSSVJaWppWrFihNWvWaMKECRo/frzWrl2r6dOnhz7VAwAARjdHAeULX/iC9u/frw0bNuhHP/qRpk6dqm3btmnp0qWhOevWrVNHR4dWrVql5uZm5eXlqaqqSikpKaE5W7duVXx8vIqLi9XR0aF58+Zp9+7diouLG7qVAQCAEctRQJGkhQsXauHChRe83eVyyefzyefzXXBOYmKiKioqVFFR4XT3AABgFOC7eAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsE58tAsARpIp659xvI0nzqh8lpTje16BLtcwVAUAsYczKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6zgKKD6fTy6XK+zi9XpDtxtj5PP5lJmZqbFjx2ru3Lk6efJk2H0EAgGtXr1aEydOVHJyshYtWqT6+vqhWQ0AAIgJjs+gXHvttWpoaAhdjh8/HrqtvLxcW7Zs0fbt23X06FF5vV4VFhaqra0tNKekpET79+9XZWWlDh8+rLNnz2rhwoXq6uoamhUBAIARz/Ffko2Pjw87a9LLGKNt27Zp48aNWrx4sSRpz549Sk9P1759+7Ry5Uq1tLRo586deuyxx1RQUCBJ2rt3r7KysnTw4EHNnz9/kMsBAACxwHFAeeONN5SZmSmPx6O8vDyVlZXpyiuvVF1dnRobG1VUVBSa6/F4NGfOHNXU1GjlypWqra1VMBgMm5OZmamcnBzV1NRcMKAEAgEFAoHQ9dbWVklSMBhUMBh0uoSI6K3L1voiJdb64IkzzrcZY8J+jlax3of+PsZj7TkxEPSgx2jsg5O1OgooeXl5+o//+A9NmzZN7733nu677z7l5+fr5MmTamxslCSlp6eHbZOenq7Tp09LkhobG5WQkKBx48b1mdO7/fls3rxZmzZt6jNeVVWlpKQkJ0uIOL/fH+0SrBArfSifNfBt753ZPXSFjGCx2ocDBw44mh8rz4nBoAc9RlMf2tvb+z3XUUBZsGBB6L+nT5+u2bNn66qrrtKePXt0ww03SJJcrvAvQzPG9Bk716fN2bBhg0pLS0PXW1tblZWVpaKiIqWmpjpZQsQEg0H5/X4VFhbK7XZHu5yoibU+5Pied7yNZ4zRvTO79cNjYxToHr1fFhjrfTjh699L1LH2nBgIetBjNPah9xWQ/hjUtxknJydr+vTpeuONN3TLLbdI6jlLkpGREZrT1NQUOqvi9XrV2dmp5ubmsLMoTU1Nys/Pv+B+PB6PPB5Pn3G32239L3Uk1BgJsdKHwXwbcaDbxbcZK3b74PTxHSvPicGgBz1GUx+crHNQfwclEAjoD3/4gzIyMjR16lR5vd6wU1WdnZ2qrq4OhY/c3Fy53e6wOQ0NDTpx4sRFAwoAABhdHJ1BWbt2rW6++WZdccUVampq0n333afW1lYtX75cLpdLJSUlKisrU3Z2trKzs1VWVqakpCQtWbJEkpSWlqYVK1ZozZo1mjBhgsaPH6+1a9dq+vTpoU/1AAAAOAoo9fX1+sd//Ee9//77uvTSS3XDDTfo5Zdf1uTJkyVJ69atU0dHh1atWqXm5mbl5eWpqqpKKSkpofvYunWr4uPjVVxcrI6ODs2bN0+7d+9WXFzc0K4MACJoyvpn+jXPE2dUPqvn/Uw2vNT11v03RbsE4LwcBZTKysqL3u5yueTz+eTz+S44JzExURUVFaqoqHCyawAAMIrwXTwAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWGdQAWXz5s1yuVwqKSkJjRlj5PP5lJmZqbFjx2ru3Lk6efJk2HaBQECrV6/WxIkTlZycrEWLFqm+vn4wpQAAgBgy4IBy9OhRPfLII7ruuuvCxsvLy7VlyxZt375dR48eldfrVWFhodra2kJzSkpKtH//flVWVurw4cM6e/asFi5cqK6uroGvBAAAxIwBBZSzZ89q6dKlevTRRzVu3LjQuDFG27Zt08aNG7V48WLl5ORoz549am9v1759+yRJLS0t2rlzpx588EEVFBRoxowZ2rt3r44fP66DBw8OzaoAAMCIFj+Qje644w7ddNNNKigo0H333Rcar6urU2Njo4qKikJjHo9Hc+bMUU1NjVauXKna2loFg8GwOZmZmcrJyVFNTY3mz5/fZ3+BQECBQCB0vbW1VZIUDAYVDAYHsoRh11uXrfVFSqz1wRNnnG8zxoT9HK3oQw/b+hCN52asHRcGajT2wclaHQeUyspK/fa3v9XRo0f73NbY2ChJSk9PDxtPT0/X6dOnQ3MSEhLCzrz0zund/lybN2/Wpk2b+oxXVVUpKSnJ6RIiyu/3R7sEK8RKH8pnDXzbe2d2D10hIxh96GFLHw4cOBC1fcfKcWGwRlMf2tvb+z3XUUB55513dPfdd6uqqkqJiYkXnOdyucKuG2P6jJ3rYnM2bNig0tLS0PXW1lZlZWWpqKhIqampDlYQOcFgUH6/X4WFhXK73dEuJ2pirQ85vucdb+MZY3TvzG798NgYBbov/jyIZfShh219OOHre9Z6uMXacWGgRmMfel8B6Q9HAaW2tlZNTU3Kzc0NjXV1demll17S9u3b9dprr0nqOUuSkZERmtPU1BQ6q+L1etXZ2anm5uawsyhNTU3Kz88/7349Ho88Hk+fcbfbbf0vdSTUGAmx0odA18D/QQl0uwa1faygDz1s6UM0n5exclwYrNHUByfrdPQm2Xnz5un48eN69dVXQ5eZM2dq6dKlevXVV3XllVfK6/WGna7q7OxUdXV1KHzk5ubK7XaHzWloaNCJEycuGFAAAMDo4ugMSkpKinJycsLGkpOTNWHChNB4SUmJysrKlJ2drezsbJWVlSkpKUlLliyRJKWlpWnFihVas2aNJkyYoPHjx2vt2rWaPn26CgoKhmhZAABgJBvQp3guZt26dero6NCqVavU3NysvLw8VVVVKSUlJTRn69atio+PV3FxsTo6OjRv3jzt3r1bcXFxQ10OAAAYgQYdUF588cWw6y6XSz6fTz6f74LbJCYmqqKiQhUVFYPdPQAAiEF8Fw8AALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdeKjXQAAIHqmrH8m4vv0xBmVz5JyfM8r0OVyvP1b9980DFXBNpxBAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB1HAWXHjh267rrrlJqaqtTUVM2ePVvPPvts6HZjjHw+nzIzMzV27FjNnTtXJ0+eDLuPQCCg1atXa+LEiUpOTtaiRYtUX18/NKsBAAAxwVFAmTRpku6//34dO3ZMx44d05e+9CV99atfDYWQ8vJybdmyRdu3b9fRo0fl9XpVWFiotra20H2UlJRo//79qqys1OHDh3X27FktXLhQXV1dQ7syAAAwYjkKKDfffLO+8pWvaNq0aZo2bZp+/OMf65JLLtHLL78sY4y2bdumjRs3avHixcrJydGePXvU3t6uffv2SZJaWlq0c+dOPfjggyooKNCMGTO0d+9eHT9+XAcPHhyWBQIAgJFnwO9B6erqUmVlpT766CPNnj1bdXV1amxsVFFRUWiOx+PRnDlzVFNTI0mqra1VMBgMm5OZmamcnJzQHAAAgHinGxw/flyzZ8/Wxx9/rEsuuUT79+/XNddcEwoY6enpYfPT09N1+vRpSVJjY6MSEhI0bty4PnMaGxsvuM9AIKBAIBC63traKkkKBoMKBoNOlxARvXXZWl+kxFofPHHG+TZjTNjP0Yo+9KAPg+9BrBxPYu342B9O1uo4oHz2s5/Vq6++qjNnzugXv/iFli9frurq6tDtLpcrbL4xps/YuT5tzubNm7Vp06Y+41VVVUpKSnK4gsjy+/3RLsEKsdKH8lkD3/bemd1DV8gIRh960IeB9+DAgQNDXEl0xcrxsT/a29v7PddxQElISNBf/dVfSZJmzpypo0eP6qGHHtL3vvc9ST1nSTIyMkLzm5qaQmdVvF6vOjs71dzcHHYWpampSfn5+Rfc54YNG1RaWhq63traqqysLBUVFSk1NdXpEiIiGAzK7/ersLBQbrc72uVETaz1Icf3vONtPGOM7p3ZrR8eG6NA98XDeiyjDz3ow+B7cMI3fxiqirxYOz72R+8rIP3hOKCcyxijQCCgqVOnyuv1yu/3a8aMGZKkzs5OVVdX64EHHpAk5ebmyu12y+/3q7i4WJLU0NCgEydOqLy8/IL78Hg88ng8fcbdbrf1v9SRUGMkxEofAl0D/wcl0O0a1Paxgj70oA8D70EsHEv+UqwcH/vDyTodBZTvf//7WrBggbKystTW1qbKykq9+OKLeu655+RyuVRSUqKysjJlZ2crOztbZWVlSkpK0pIlSyRJaWlpWrFihdasWaMJEyZo/PjxWrt2raZPn66CggJnqwQAADHLUUB57733tGzZMjU0NCgtLU3XXXednnvuORUWFkqS1q1bp46ODq1atUrNzc3Ky8tTVVWVUlJSQvexdetWxcfHq7i4WB0dHZo3b552796tuLi4oV0ZAAAYsRwFlJ07d170dpfLJZ/PJ5/Pd8E5iYmJqqioUEVFhZNdAwCAUYTv4gEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHUcBZfPmzfrCF76glJQUXXbZZbrlllv02muvhc0xxsjn8ykzM1Njx47V3LlzdfLkybA5gUBAq1ev1sSJE5WcnKxFixapvr5+8KsBAAAxwVFAqa6u1h133KGXX35Zfr9fn3zyiYqKivTRRx+F5pSXl2vLli3avn27jh49Kq/Xq8LCQrW1tYXmlJSUaP/+/aqsrNThw4d19uxZLVy4UF1dXUO3MgAAMGLFO5n83HPPhV3ftWuXLrvsMtXW1upv//ZvZYzRtm3btHHjRi1evFiStGfPHqWnp2vfvn1auXKlWlpatHPnTj322GMqKCiQJO3du1dZWVk6ePCg5s+fP0RLAwAAI5WjgHKulpYWSdL48eMlSXV1dWpsbFRRUVFojsfj0Zw5c1RTU6OVK1eqtrZWwWAwbE5mZqZycnJUU1Nz3oASCAQUCARC11tbWyVJwWBQwWBwMEsYNr112VpfpMRaHzxxxvk2Y0zYz9GKPvSgD4PvQawcT2Lt+NgfTtY64IBijFFpaan+5m/+Rjk5OZKkxsZGSVJ6enrY3PT0dJ0+fTo0JyEhQePGjeszp3f7c23evFmbNm3qM15VVaWkpKSBLiEi/H5/tEuwQqz0oXzWwLe9d2b30BUygtGHHvRh4D04cODAEFcSXbFyfOyP9vb2fs8dcEC588479fvf/16HDx/uc5vL5Qq7bozpM3aui83ZsGGDSktLQ9dbW1uVlZWloqIipaamDqD64RcMBuX3+1VYWCi32x3tcqIm1vqQ43ve8TaeMUb3zuzWD4+NUaD74s+DWEYfetCHwffghC823goQa8fH/uh9BaQ/BhRQVq9eraefflovvfSSJk2aFBr3er2Ses6SZGRkhMabmppCZ1W8Xq86OzvV3NwcdhalqalJ+fn5592fx+ORx+PpM+52u63/pY6EGiMhVvoQ6Br4PyiBbtegto8V9KEHfRh4D2LhWPKXYuX42B9O1unoUzzGGN1555166qmn9MILL2jq1Klht0+dOlVerzfsdFVnZ6eqq6tD4SM3N1dutztsTkNDg06cOHHBgAIAAEYXR2dQ7rjjDu3bt0//+Z//qZSUlNB7RtLS0jR27Fi5XC6VlJSorKxM2dnZys7OVllZmZKSkrRkyZLQ3BUrVmjNmjWaMGGCxo8fr7Vr12r69OmhT/UAAIDRzVFA2bFjhyRp7ty5YeO7du3SN77xDUnSunXr1NHRoVWrVqm5uVl5eXmqqqpSSkpKaP7WrVsVHx+v4uJidXR0aN68edq9e7fi4uIGtxoAABATHAUUYz79I2Eul0s+n08+n++CcxITE1VRUaGKigonuwcAAKME38UDAACsQ0ABAADWIaAAAADrDOpP3QMAEGlT1j8T7RIce+v+m6JdwojDGRQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDqOA8pLL72km2++WZmZmXK5XPrlL38ZdrsxRj6fT5mZmRo7dqzmzp2rkydPhs0JBAJavXq1Jk6cqOTkZC1atEj19fWDWggAAIgdjgPKRx99pOuvv17bt28/7+3l5eXasmWLtm/frqNHj8rr9aqwsFBtbW2hOSUlJdq/f78qKyt1+PBhnT17VgsXLlRXV9fAVwIAAGJGvNMNFixYoAULFpz3NmOMtm3bpo0bN2rx4sWSpD179ig9PV379u3TypUr1dLSop07d+qxxx5TQUGBJGnv3r3KysrSwYMHNX/+/EEsBwAAxALHAeVi6urq1NjYqKKiotCYx+PRnDlzVFNTo5UrV6q2tlbBYDBsTmZmpnJyclRTU3PegBIIBBQIBELXW1tbJUnBYFDBYHAolzBkeuuytb5IibU+eOKM823GmLCfoxV96EEfRmcPzncMjLXjY384WeuQBpTGxkZJUnp6eth4enq6Tp8+HZqTkJCgcePG9ZnTu/25Nm/erE2bNvUZr6qqUlJS0lCUPmz8fn+0S7BCrPShfNbAt713ZvfQFTKC0Yce9GF09eDAgQMXvC1Wjo/90d7e3u+5QxpQerlcrrDrxpg+Y+e62JwNGzaotLQ0dL21tVVZWVkqKipSamrq4AseBsFgUH6/X4WFhXK73dEuJ2pirQ85vucdb+MZY3TvzG798NgYBbov/jyIZfShB30YnT044ev76kCsHR/7o/cVkP4Y0oDi9Xol9ZwlycjICI03NTWFzqp4vV51dnaqubk57CxKU1OT8vPzz3u/Ho9HHo+nz7jb7bb+lzoSaoyEWOlDoGvgB9NAt2tQ28cK+tCDPoyuHlzs+Bcrx8f+cLLOIf07KFOnTpXX6w07XdXZ2anq6upQ+MjNzZXb7Q6b09DQoBMnTlwwoAAAgNHF8RmUs2fP6n/+539C1+vq6vTqq69q/PjxuuKKK1RSUqKysjJlZ2crOztbZWVlSkpK0pIlSyRJaWlpWrFihdasWaMJEyZo/PjxWrt2raZPnx76VA8AABjdHAeUY8eO6e/+7u9C13vfG7J8+XLt3r1b69atU0dHh1atWqXm5mbl5eWpqqpKKSkpoW22bt2q+Ph4FRcXq6OjQ/PmzdPu3bsVFxc3BEsCAAAjneOAMnfuXBlz4Y+GuVwu+Xw++Xy+C85JTExURUWFKioqnO4eAACMAsPyKR6gP6asfybaJQAALMWXBQIAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALBOfLQLAAAg1k1Z/0yfMU+cUfksKcf3vAJdrihUdXFv3X9TVPfPGRQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA5/6j5GnO/PKNvA9j/lDACwE2dQAACAdQgoAADAOlENKA8//LCmTp2qxMRE5ebm6tChQ9EsBwAAWCJqAeWJJ55QSUmJNm7cqN/97nf64he/qAULFujtt9+OVkkAAMASUQsoW7Zs0YoVK/Stb31LV199tbZt26asrCzt2LEjWiUBAABLROVTPJ2dnaqtrdX69evDxouKilRTU9NnfiAQUCAQCF1vaWmRJH344YcKBoNDXl/e5v836PvwjDH6wYxufX7jUwp0D/+nV2z9OFZ8t1F7e7fig2PUFYE+2Ige9KAPPegDPehlex8++OCDIb/PtrY2SZIx5tMnmyj485//bCSZX//612HjP/7xj820adP6zL/nnnuMJC5cuHDhwoVLDFzeeeedT80KUf0fb5crPDEaY/qMSdKGDRtUWloaut7d3a0PP/xQEyZMOO98G7S2tiorK0vvvPOOUlNTo11O1NAHetCLPvSgD/Sg12jsgzFGbW1tyszM/NS5UQkoEydOVFxcnBobG8PGm5qalJ6e3me+x+ORx+MJG/vMZz4znCUOmdTU1FHzwLsY+kAPetGHHvSBHvQabX1IS0vr17yovEk2ISFBubm58vv9YeN+v1/5+fnRKAkAAFgkai/xlJaWatmyZZo5c6Zmz56tRx55RG+//ba+/e1vR6skAABgiagFlFtvvVUffPCBfvSjH6mhoUE5OTk6cOCAJk+eHK2ShpTH49E999zT56Wp0YY+0INe9KEHfaAHvejDxbmM6c9nfQAAACKH7+IBAADWIaAAAADrEFAAAIB1CCgAAMA6BJQh1NzcrGXLliktLU1paWlatmyZzpw50+/tV65cKZfLpW3btg1bjcPNaQ+CwaC+973vafr06UpOTlZmZqZuu+02vfvuu5Eregg8/PDDmjp1qhITE5Wbm6tDhw5ddH51dbVyc3OVmJioK6+8Uv/2b/8WoUqHl5M+PPXUUyosLNSll16q1NRUzZ49W88//3wEqx0eTh8LvX79618rPj5en//854e3wAhx2odAIKCNGzdq8uTJ8ng8uuqqq/Tv//7vEap2+Djtw+OPP67rr79eSUlJysjI0De/+c1h+U6cEWFIvlwHxhhjvvzlL5ucnBxTU1NjampqTE5Ojlm4cGG/tt2/f7+5/vrrTWZmptm6devwFjqMnPbgzJkzpqCgwDzxxBPmj3/8ozly5IjJy8szubm5Eax6cCorK43b7TaPPvqoOXXqlLn77rtNcnKyOX369Hnnv/nmmyYpKcncfffd5tSpU+bRRx81brfbPPnkkxGufGg57cPdd99tHnjgAfPKK6+Y119/3WzYsMG43W7z29/+NsKVDx2nPeh15swZc+WVV5qioiJz/fXXR6bYYTSQPixatMjk5eUZv99v6urqzG9+85s+39c20jjtw6FDh8yYMWPMQw89ZN58801z6NAhc+2115pbbrklwpXbgYAyRE6dOmUkmZdffjk0duTIESPJ/PGPf7zotvX19ebyyy83J06cMJMnTx6xAWUwPfhLr7zyipH0qQd1W8yaNct8+9vfDhv73Oc+Z9avX3/e+evWrTOf+9znwsZWrlxpbrjhhmGrMRKc9uF8rrnmGrNp06ahLi1iBtqDW2+91fzgBz8w99xzT0wEFKd9ePbZZ01aWpr54IMPIlFexDjtw7/+67+aK6+8MmzsJz/5iZk0adKw1WgzXuIZIkeOHFFaWpry8vJCYzfccIPS0tJUU1Nzwe26u7u1bNkyffe739W1114biVKHzUB7cK6Wlha5XK4R8X1LnZ2dqq2tVVFRUdh4UVHRBdd85MiRPvPnz5+vY8eOKRgMDlutw2kgfThXd3e32traNH78+OEocdgNtAe7du3Sn/70J91zzz3DXWJEDKQPTz/9tGbOnKny8nJdfvnlmjZtmtauXauOjo5IlDwsBtKH/Px81dfX68CBAzLG6L333tOTTz6pm266KRIlWyeq32YcSxobG3XZZZf1Gb/sssv6fCniX3rggQcUHx+vu+66azjLi4iB9uAvffzxx1q/fr2WLFkyIr486/3331dXV1efL7lMT0+/4JobGxvPO/+TTz7R+++/r4yMjGGrd7gMpA/nevDBB/XRRx+puLh4OEocdgPpwRtvvKH169fr0KFDio+PjcPxQPrw5ptv6vDhw0pMTNT+/fv1/vvva9WqVfrwww9H7PtQBtKH/Px8Pf7447r11lv18ccf65NPPtGiRYtUUVERiZKtwxmUT+Hz+eRyuS56OXbsmCTJ5XL12d4Yc95xSaqtrdVDDz2k3bt3X3CODYazB38pGAzq61//urq7u/Xwww8P+TqG07nr+7Q1n2/++cZHGqd96PWzn/1MPp9PTzzxxHlD7kjS3x50dXVpyZIl2rRpk6ZNmxap8iLGyWOhu7tbLpdLjz/+uGbNmqWvfOUr2rJli3bv3j2iz6JIzvpw6tQp3XXXXfqXf/kX1dbW6rnnnlNdXd2o/Y662Ijsw+jOO+/U17/+9YvOmTJlin7/+9/rvffe63Pb//7v//ZJ0L0OHTqkpqYmXXHFFaGxrq4urVmzRtu2bdNbb701qNqHynD2oFcwGFRxcbHq6ur0wgsvjIizJ5I0ceJExcXF9fk/oqampguu2ev1nnd+fHy8JkyYMGy1DqeB9KHXE088oRUrVujnP/+5CgoKhrPMYeW0B21tbTp27Jh+97vf6c4775TU8w+1MUbx8fGqqqrSl770pYjUPpQG8ljIyMjQ5ZdfrrS0tNDY1VdfLWOM6uvrlZ2dPaw1D4eB9GHz5s268cYb9d3vfleSdN111yk5OVlf/OIXdd99943Is6uDQUD5FBMnTtTEiRM/dd7s2bPV0tKiV155RbNmzZIk/eY3v1FLS4vy8/PPu82yZcv6HJDnz5+vZcuW6Zvf/Obgix8iw9kD6f/CyRtvvKFf/epXI+of6YSEBOXm5srv9+vv//7vQ+N+v19f/epXz7vN7Nmz9V//9V9hY1VVVZo5c6bcbvew1jtcBtIHqefMye23366f/exnI/51dqc9SE1N1fHjx8PGHn74Yb3wwgt68sknNXXq1GGveTgM5LFw44036uc//7nOnj2rSy65RJL0+uuva8yYMZo0aVJE6h5qA+lDe3t7n5f64uLiJP3fWdZRJTrvzY1NX/7yl811111njhw5Yo4cOWKmT5/e5yO2n/3sZ81TTz11wfsYyZ/iMcZ5D4LBoFm0aJGZNGmSefXVV01DQ0PoEggEorEEx3o/Srhz505z6tQpU1JSYpKTk81bb71ljDFm/fr1ZtmyZaH5vR8z/s53vmNOnTpldu7cGVMfM+5vH/bt22fi4+PNT3/607Df+5kzZ6K1hEFz2oNzxcqneJz2oa2tzUyaNMn8wz/8gzl58qSprq422dnZ5lvf+la0ljAknPZh165dJj4+3jz88MPmT3/6kzl8+LCZOXOmmTVrVrSWEFUElCH0wQcfmKVLl5qUlBSTkpJili5dapqbm8PmSDK7du264H2M9IDitAd1dXVG0nkvv/rVryJe/0D99Kc/NZMnTzYJCQnmr//6r011dXXotuXLl5s5c+aEzX/xxRfNjBkzTEJCgpkyZYrZsWNHhCseHk76MGfOnPP+3pcvXx75woeQ08fCX4qVgGKM8z784Q9/MAUFBWbs2LFm0qRJprS01LS3t0e46qHntA8/+clPzDXXXGPGjh1rMjIyzNKlS019fX2Eq7aDy5jReN4IAADYjE/xAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCd/w/VAoaYRYF+lQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(ITE_pred_fact).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16414f33-1f8c-49fe-8da9-f889b4eabf27",
   "metadata": {},
   "source": [
    "# Training a PEACE model with all our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077104c5-3a1b-411b-b109-368fa8d7748f",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a1adf3-3043-413f-b8ba-d4884bd58b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frenk_sent_train = np.load('outs/frenk/sent_train_outs.npy')\n",
    "frenk_aggr_train = np.load('outs/frenk/aggr_train_outs.npy')\n",
    "frenk_gen_train = np.load('outs/frenk/gen_train_outs.npy')\n",
    "\n",
    "frenk_sent_test = np.load('outs/frenk/sent_test_outs.npy')\n",
    "frenk_aggr_test = np.load('outs/frenk/aggr_test_outs.npy')\n",
    "frenk_gen_test = np.load('outs/frenk/gen_test_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59cc9f9-2554-49b4-9223-4caab6e7cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghc_sent_train = np.load('outs/ghc/sent_train_outs.npy')\n",
    "ghc_aggr_train = np.load('outs/ghc/aggr_train_outs.npy')\n",
    "ghc_gen_train = np.load('outs/ghc/gen_train_outs.npy')\n",
    "\n",
    "ghc_sent_test = np.load('outs/ghc/sent_test_outs.npy')\n",
    "ghc_aggr_test = np.load('outs/ghc/aggr_test_outs.npy')\n",
    "ghc_gen_test = np.load('outs/ghc/gen_test_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81d55605-2b74-4b41-a95f-4c34266cf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_sent_train = np.load('outs/try/sent_train_outs.npy')\n",
    "try_aggr_train = np.load('outs/try/aggr_train_outs.npy')\n",
    "try_gen_train = np.load('outs/try/gen_train_outs.npy')\n",
    "\n",
    "try_sent_test = np.load('outs/try/sent_test_outs.npy')\n",
    "try_aggr_test = np.load('outs/try/aggr_test_outs.npy')\n",
    "try_gen_test = np.load('outs/try/gen_test_outs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "501e61df-35d7-41bc-877e-136837f0fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train = np.concatenate([frenk_sent_train,frenk_sent_test,ghc_sent_train,ghc_sent_test,try_sent_train,try_sent_test],axis=0)\n",
    "aggr_train = np.concatenate([frenk_aggr_train,frenk_aggr_test,ghc_aggr_train,ghc_aggr_test,try_aggr_train,try_aggr_test],axis=0)\n",
    "gen_train = np.concatenate([frenk_gen_train,frenk_gen_test,ghc_gen_train,ghc_gen_test,try_gen_train,try_gen_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5d826f-fd4b-4836-8506-59caa3d721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_train = np.concatenate([sent_train,aggr_train,gen_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a0f74-5c0e-41b1-a2b3-acb54c7c420f",
   "metadata": {},
   "source": [
    "## Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95b1b8fe-2f42-4457-8db3-8fcbf857072f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "98e5e4c1ef214179bcd5a6e6f3b9632d",
      "482795395a764b0b8ac6167c358c2bf8",
      "d4bb70f128f64cdd9339e4f3cb83f3b4",
      "7570723a96df45679a13d7c438d466e5",
      "6b2d2176afd643c796985f1353f36323",
      "d247e2738a5e423cb06dd55693d449d0",
      "4491981ccfec475abca58b9abe17e276",
      "99a31e2a373f4a1fa93a2bf9f01edbf1",
      "748e0715760d4d15b208c0aeb2b04356",
      "f5d04592b62d4a6e97e25ba5e9a32326",
      "a91f49931eea4d92b6c1d2b20c4aefcf",
      "7a64ed0166b945a2ae0ddb9ff89bbd56",
      "a51747d13e7b465581f777211ec9549b",
      "f4b74ca0fa154f43b9f789ab34852d4e",
      "b4c3c15330494d79ab5b4e8c6551a3fe",
      "036ad7eb94674978b468a920b137909f",
      "52f2023f766144c493c01cb4d5584bea",
      "17f1c3680b77467787907339c85483a2",
      "197cc63ffeb0453fba7730a9b8bd531d",
      "536d0694580e46ad9356586aea88627d",
      "e5b7fe1e3cf544a093c3bbc1f075545a",
      "c1e07d59106544bdbd0cde97380c88db",
      "f272ebd214f143579a747d37f06f8578",
      "3b76aca2cab644f4adb0a9c24b33865d",
      "4f658c94ca774adeb6c27f0b8d68b368",
      "f8d2fab6726a49e8b8443783f5f20911",
      "4f240765e11f47e5b8110c3cb2f81b35",
      "a4029f83f1294ca981a62817ac835484",
      "81c392bd546145eabd2bd1ff0b246911",
      "4d7af20dd05f494fa1dd92ae73fe158b",
      "5933c72a748b4db58078f517db5c5120",
      "8e33c271de1744bc8d0b6f67c1101dcc",
      "a6ce855654cc4ca295ce3689984ac226",
      "9ea59faa0bd9499f8c7cca5daf9b76e6",
      "29c4fec6dab24c939932e910db29f9ff",
      "c735bcf28dde4305a1642a2bdbf3dfcb",
      "f5970bf0a69842e692041a7a2c21dfb1",
      "5e1988dc726b441ebc1d264a98b83fbc",
      "ad9364544e214b8483520020a3b87df2",
      "701e0f2fbad3463b9c66e8a7e4949144",
      "2a314420428a4ce68ee073a113a1865e",
      "cb1f8f1990674960b54a418a6b943bf4",
      "e87b2bd9a2ed42759ef716c07a882ad5",
      "3ded0e0a04d848288c4e07fb2ccb0b18",
      "729406de6279478cac75ccb416ce32e3",
      "7333fc5f3900426bb7d7434e5eb022eb",
      "0c1bf462bbd546b79fde5184783b20ca",
      "fc2a3ed815b547509babfe56b6b0028c",
      "012301170183417b8ef37fc3be9a83a5",
      "35f31858d8874821bcaa11016848b20a",
      "982671eca74a4ca0b2d088547299cc8f",
      "2b632fea606d45159af0119fa75608e9",
      "aae8849e337343f3af0ecf16e3af771c",
      "4d35111788134cb39ed708ac586b83eb",
      "73db15a993774ae1bda701fe24873603",
      "144c0ffba3594009a8aa65b559c0b952",
      "3e9439cf81a945189375acb8c4b1cc17",
      "54d65145ad394f2c87a90e261677f32b",
      "7b621ddc28824e0a9f44e5ed8b07929d",
      "cc1490fef2964807b77fbdda5976e7a8",
      "ca55578fb1e34028af4b62f202f0c052",
      "03fb007c6c0449c2944e714a0a0bb9e5",
      "a0d76c86d1134f1499635b9ac8060808",
      "734d37cfc6cf470da494439db51cd41f",
      "ebf45b42aa1a48a69981ed743e1ffd4c",
      "fbb555562628439a8688074da28c6cd6"
     ]
    },
    "id": "XLUg9YO7w9eC",
    "outputId": "3058b858-8eb3-44fc-da98-7cccb19cd65e"
   },
   "outputs": [],
   "source": [
    "#FRENK dataset\n",
    "df_train = pd.read_csv('data/frenk_train.tsv',sep='\\t')\n",
    "frenk_label_train = df_train[\"label\"].to_numpy()\n",
    "\n",
    "df_test = pd.read_csv('data/frenk_test.tsv',sep='\\t')\n",
    "frenk_label_test = df_test[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbbc058-e4b6-45b6-a083-a07b3bef84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hate_labels(labels):\n",
    "    hate_labels = np.zeros(len(labels))\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i].any():\n",
    "            hate_labels[i] = 1\n",
    "    return hate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a437e7ce-de58-4290-b0c6-c95e22a09e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gab dataset\n",
    "df_train = pd.read_csv('data/ghc_train_8404.tsv',sep='\\t')\n",
    "labels = df_train[[\"hd\",\"cv\"]].to_numpy()\n",
    "ghc_label_train = get_hate_labels(labels)\n",
    "\n",
    "df_test = pd.read_csv('data/ghc_test_2301.tsv',sep='\\t')\n",
    "labels = df_test[[\"hd\",\"cv\"]].to_numpy()\n",
    "ghc_label_test = get_hate_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd39afb-12fa-4242-b91d-9f1de6b36bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twi-Red-You dataset\n",
    "df_train = pd.read_csv('data/try_train_8404.tsv',sep='\\t')\n",
    "try_label_train = df_train['hate'].to_numpy()\n",
    "\n",
    "df_test = pd.read_csv('data/try_test_2301.tsv',sep='\\t')\n",
    "try_label_test = df_test['hate'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e3bfeb4-f7b8-44ef-bbfd-32e39f0c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.concatenate([frenk_label_train,frenk_label_test,ghc_label_train,ghc_label_test,try_label_train,try_label_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "011266dd-b088-4e38-bc9f-1cef43cd8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights = compute_class_weight('balanced', classes=np.unique(label_train), y=label_train)\n",
    "c_weights = {0:c_weights[0], 1:c_weights[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330df37-4a91-4ee7-a30a-ccd76c9daae5",
   "metadata": {},
   "source": [
    "## Training the PEACE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3722973-b535-4d57-b1d0-5054c27d84ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5212 - accuracy: 0.7232 - val_loss: 0.7869 - val_accuracy: 0.5374\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4909 - accuracy: 0.7387 - val_loss: 0.5246 - val_accuracy: 0.7232\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4790 - accuracy: 0.7446 - val_loss: 0.5292 - val_accuracy: 0.7217\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 5s 6ms/step - loss: 0.4680 - accuracy: 0.7482 - val_loss: 0.6157 - val_accuracy: 0.6747\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4607 - accuracy: 0.7506 - val_loss: 0.4979 - val_accuracy: 0.7388\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4480 - accuracy: 0.7568 - val_loss: 0.5992 - val_accuracy: 0.6734\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 5s 6ms/step - loss: 0.4370 - accuracy: 0.7601 - val_loss: 0.5649 - val_accuracy: 0.6912\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4263 - accuracy: 0.7660 - val_loss: 0.6097 - val_accuracy: 0.6554\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4149 - accuracy: 0.7696 - val_loss: 0.6499 - val_accuracy: 0.6382\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4049 - accuracy: 0.7750 - val_loss: 0.5493 - val_accuracy: 0.6902\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.5197 - accuracy: 0.7222 - val_loss: 0.6222 - val_accuracy: 0.6429\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4921 - accuracy: 0.7383 - val_loss: 0.6337 - val_accuracy: 0.6423\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4776 - accuracy: 0.7424 - val_loss: 0.5749 - val_accuracy: 0.6775\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4662 - accuracy: 0.7472 - val_loss: 0.6557 - val_accuracy: 0.6308\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 6s 6ms/step - loss: 0.4572 - accuracy: 0.7511 - val_loss: 0.6195 - val_accuracy: 0.6389\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4454 - accuracy: 0.7580 - val_loss: 0.6473 - val_accuracy: 0.6298\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4346 - accuracy: 0.7616 - val_loss: 0.5435 - val_accuracy: 0.7182\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 5s 6ms/step - loss: 0.4236 - accuracy: 0.7678 - val_loss: 0.6774 - val_accuracy: 0.6080\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4112 - accuracy: 0.7756 - val_loss: 0.6471 - val_accuracy: 0.6647\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4000 - accuracy: 0.7795 - val_loss: 0.6317 - val_accuracy: 0.6529\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5166 - accuracy: 0.7246 - val_loss: 0.6374 - val_accuracy: 0.6535\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4910 - accuracy: 0.7390 - val_loss: 0.6603 - val_accuracy: 0.6192\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4774 - accuracy: 0.7445 - val_loss: 0.6508 - val_accuracy: 0.6295\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4675 - accuracy: 0.7517 - val_loss: 0.6771 - val_accuracy: 0.6245\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4573 - accuracy: 0.7527 - val_loss: 0.6393 - val_accuracy: 0.6554\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 5s 6ms/step - loss: 0.4479 - accuracy: 0.7573 - val_loss: 0.5231 - val_accuracy: 0.7388\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4347 - accuracy: 0.7646 - val_loss: 0.6891 - val_accuracy: 0.6382\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4251 - accuracy: 0.7702 - val_loss: 0.5678 - val_accuracy: 0.6983\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4126 - accuracy: 0.7732 - val_loss: 0.5811 - val_accuracy: 0.6709\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 5s 6ms/step - loss: 0.3975 - accuracy: 0.7825 - val_loss: 0.5346 - val_accuracy: 0.6924\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5167 - accuracy: 0.7265 - val_loss: 0.6991 - val_accuracy: 0.5713\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4926 - accuracy: 0.7364 - val_loss: 0.5899 - val_accuracy: 0.6678\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4777 - accuracy: 0.7487 - val_loss: 0.5829 - val_accuracy: 0.6672\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4676 - accuracy: 0.7495 - val_loss: 0.5639 - val_accuracy: 0.6715\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4550 - accuracy: 0.7535 - val_loss: 0.5823 - val_accuracy: 0.6753\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4462 - accuracy: 0.7596 - val_loss: 0.5617 - val_accuracy: 0.7098\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4341 - accuracy: 0.7667 - val_loss: 0.6411 - val_accuracy: 0.6438\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4250 - accuracy: 0.7696 - val_loss: 0.5795 - val_accuracy: 0.6800\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4131 - accuracy: 0.7740 - val_loss: 0.5718 - val_accuracy: 0.6955\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4021 - accuracy: 0.7815 - val_loss: 0.5641 - val_accuracy: 0.6993\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5185 - accuracy: 0.7245 - val_loss: 0.5417 - val_accuracy: 0.6974\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4905 - accuracy: 0.7400 - val_loss: 0.6183 - val_accuracy: 0.6694\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4784 - accuracy: 0.7465 - val_loss: 0.6270 - val_accuracy: 0.6451\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4687 - accuracy: 0.7483 - val_loss: 0.6323 - val_accuracy: 0.6709\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4563 - accuracy: 0.7565 - val_loss: 0.5327 - val_accuracy: 0.7214\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4463 - accuracy: 0.7582 - val_loss: 0.6490 - val_accuracy: 0.6292\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4353 - accuracy: 0.7664 - val_loss: 0.5836 - val_accuracy: 0.6908\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.4222 - accuracy: 0.7703 - val_loss: 0.6308 - val_accuracy: 0.6759\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4116 - accuracy: 0.7780 - val_loss: 0.6571 - val_accuracy: 0.6432\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4002 - accuracy: 0.7833 - val_loss: 0.5325 - val_accuracy: 0.7092\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 5s 4ms/step - loss: 0.5178 - accuracy: 0.7234 - val_loss: 0.6043 - val_accuracy: 0.6544\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4918 - accuracy: 0.7402 - val_loss: 0.5705 - val_accuracy: 0.6952\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4797 - accuracy: 0.7479 - val_loss: 0.5906 - val_accuracy: 0.6778\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4695 - accuracy: 0.7515 - val_loss: 0.6622 - val_accuracy: 0.6096\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4595 - accuracy: 0.7527 - val_loss: 0.5783 - val_accuracy: 0.6834\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4511 - accuracy: 0.7532 - val_loss: 0.5852 - val_accuracy: 0.6759\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4390 - accuracy: 0.7577 - val_loss: 0.6332 - val_accuracy: 0.6345\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4308 - accuracy: 0.7610 - val_loss: 0.5570 - val_accuracy: 0.7120\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4205 - accuracy: 0.7641 - val_loss: 0.6486 - val_accuracy: 0.6510\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4105 - accuracy: 0.7725 - val_loss: 0.5823 - val_accuracy: 0.6840\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5156 - accuracy: 0.7228 - val_loss: 0.6429 - val_accuracy: 0.5837\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4916 - accuracy: 0.7367 - val_loss: 0.5747 - val_accuracy: 0.6896\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4782 - accuracy: 0.7418 - val_loss: 0.5818 - val_accuracy: 0.6722\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4674 - accuracy: 0.7445 - val_loss: 0.5694 - val_accuracy: 0.6809\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4573 - accuracy: 0.7436 - val_loss: 0.5512 - val_accuracy: 0.6921\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4456 - accuracy: 0.7544 - val_loss: 0.7278 - val_accuracy: 0.5682\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4361 - accuracy: 0.7567 - val_loss: 0.5999 - val_accuracy: 0.6619\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4267 - accuracy: 0.7625 - val_loss: 0.5900 - val_accuracy: 0.6806\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4175 - accuracy: 0.7670 - val_loss: 0.6681 - val_accuracy: 0.5931\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4041 - accuracy: 0.7754 - val_loss: 0.6297 - val_accuracy: 0.6448\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.5176 - accuracy: 0.7219 - val_loss: 0.6027 - val_accuracy: 0.6790\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4910 - accuracy: 0.7409 - val_loss: 0.6421 - val_accuracy: 0.6385\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4796 - accuracy: 0.7468 - val_loss: 0.5993 - val_accuracy: 0.6566\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7493 - val_loss: 0.6771 - val_accuracy: 0.6395\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4581 - accuracy: 0.7538 - val_loss: 0.5854 - val_accuracy: 0.6653\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4468 - accuracy: 0.7626 - val_loss: 0.6279 - val_accuracy: 0.6382\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4347 - accuracy: 0.7653 - val_loss: 0.5559 - val_accuracy: 0.7086\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4235 - accuracy: 0.7723 - val_loss: 0.6492 - val_accuracy: 0.6519\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4135 - accuracy: 0.7764 - val_loss: 0.5494 - val_accuracy: 0.7214\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4041 - accuracy: 0.7804 - val_loss: 0.6885 - val_accuracy: 0.6298\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.5183 - accuracy: 0.7244 - val_loss: 0.6865 - val_accuracy: 0.5943\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4920 - accuracy: 0.7389 - val_loss: 0.6776 - val_accuracy: 0.6435\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4807 - accuracy: 0.7419 - val_loss: 0.7059 - val_accuracy: 0.5775\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4683 - accuracy: 0.7471 - val_loss: 0.5983 - val_accuracy: 0.6544\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4571 - accuracy: 0.7507 - val_loss: 0.6839 - val_accuracy: 0.6326\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.4483 - accuracy: 0.7567 - val_loss: 0.5302 - val_accuracy: 0.7126\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4345 - accuracy: 0.7604 - val_loss: 0.6195 - val_accuracy: 0.6513\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4205 - accuracy: 0.7658 - val_loss: 0.6124 - val_accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4115 - accuracy: 0.7780 - val_loss: 0.6032 - val_accuracy: 0.6529\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.7774 - val_loss: 0.5728 - val_accuracy: 0.6843\n",
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 3ms/step - loss: 0.5165 - accuracy: 0.7229 - val_loss: 0.6433 - val_accuracy: 0.6351\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4921 - accuracy: 0.7398 - val_loss: 0.6739 - val_accuracy: 0.6441\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 4s 5ms/step - loss: 0.4774 - accuracy: 0.7438 - val_loss: 0.6537 - val_accuracy: 0.6351\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4683 - accuracy: 0.7481 - val_loss: 0.6089 - val_accuracy: 0.6336\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4559 - accuracy: 0.7539 - val_loss: 0.5096 - val_accuracy: 0.7238\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4456 - accuracy: 0.7605 - val_loss: 0.5469 - val_accuracy: 0.6933\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 5s 5ms/step - loss: 0.4360 - accuracy: 0.7658 - val_loss: 0.6211 - val_accuracy: 0.6653\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4245 - accuracy: 0.7704 - val_loss: 0.5651 - val_accuracy: 0.6908\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.4144 - accuracy: 0.7748 - val_loss: 0.6551 - val_accuracy: 0.6211\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.4045 - accuracy: 0.7782 - val_loss: 0.6235 - val_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_hate_model = None\n",
    "for i in range(n_avg):\n",
    "    hate_model = Sequential([\n",
    "          Flatten(),\n",
    "          Dense(128, activation='relu'),\n",
    "          Dense(128, activation='relu'),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "    hate_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = hate_model.fit(conc_train, label_train, class_weight=c_weights, epochs=10, batch_size=32, validation_split=0.1)\n",
    "    #class_weight=c_weights\n",
    "    \n",
    "    # Get the last accuracy\n",
    "    last_val_acc = history.history['val_accuracy'][-1]\n",
    "    # Compare with the best accuracy\n",
    "    if last_val_acc > best_val_acc:\n",
    "        best_val_acc = last_val_acc\n",
    "        best_hate_model = hate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11efd5eb-c8ee-4514-b15b-589c266d1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ITE_model/models/PEACE_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_hate_model.save('ITE_model/models/PEACE_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
