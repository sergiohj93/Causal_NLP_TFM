{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19822ddc-70dc-4f45-a61a-aeb9fd719d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp39-cp39-win_amd64.whl (798 kB)\n",
      "                                              0.0/798.7 kB ? eta -:--:--\n",
      "     --                                      41.0/798.7 kB 1.9 MB/s eta 0:00:01\n",
      "     ----                                    92.2/798.7 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------                           256.0/798.7 kB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------                 481.3/798.7 kB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------            583.7/798.7 kB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 798.7/798.7 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5f6111-d01c-4cf3-9935-b0a3617507cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_turbo = \"gpt-4-turbo\"\n",
    "gpt3_5_turbo = \"gpt-3.5-turbo-0125\"\n",
    "gpt3_5_turbo_instruct = \"gpt-3.5-turbo-instruct\"\n",
    "gpt3_5_turbo_1106 = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0df0e54-c4a8-4843-bd0e-c00756fa4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpt3_5_turbo\n",
    "n_responses = 5\n",
    "n_samples = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67a0f9d0-fd6c-43d2-a5f5-db73f0d68e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prices: $/1M tokens \n",
    "def switch_prices(model):\n",
    "    if model == gpt4_turbo:\n",
    "        return [10,30]\n",
    "    elif model == gpt3_5_turbo:\n",
    "        return [0.50,1.50]\n",
    "    elif model == gpt3_5_turbo_instruct:\n",
    "        return [1.50,2]\n",
    "    elif model == gpt3_5_turbo_1106:\n",
    "        return [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2359801-5caa-4094-bd07-ad064a230208",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = switch_prices(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6057ce9d-d1bd-40bc-8a69-a7172f708519",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fb9a55c-6802-492c-b1b5-57006c783a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You must revise a given sentence INCREASING its OFFENSIVENESS without changing its MEANING. Here are a few examples of what I would like:\n",
    "<Example 1> Sentence: Trust me, Mr Jackson, with this attitude, it is not \"\"your\"\" country.\n",
    "Revised Sentence: Listen up, Mr. Jackson, with that appalling attitude of yours, this country couldn't be further from belonging to someone like you. </Example 1>\n",
    "<Example 2> Sentence: I do need help - help explaining to religious fanatics, that we live in 2014.\n",
    "Revised Sentence: I absolutely require assistance - assistance to elucidate to those ignorant religious zealots, stuck in their archaic beliefs, that we are indeed living in the year 2014, not the Dark Ages. </Example 2>\n",
    "<Example 3> Sentence:  John, you obviously don't understand our laws or our Constitution.\n",
    "Revised Sentence: John, it's painfully evident that your pea-sized brain can't understand our laws or our Constitution. </Example 3>\n",
    "<Example 4> Sentence: We are ALL tired of waiting . . realize something.\n",
    "Revised Sentence: We're ALL damn sick and tired of waiting. Pull your head out of your rear end and realize something! </Example 4>\n",
    "Sentence: You need to respect and be tolerant of peoples right to say no. Simple as that\n",
    "Revised Sentence:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e776110-f060-42b9-af13-af5c10160bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = '''You need to get it through your thick skull and show some damn respect, acknowledging and tolerating people's right to say no. It's as simple as that, you ignorant fool.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57ac5702-0541-41b2-8d27-7fba7ad8169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = len(encoding.encode(prompt))\n",
    "response_tokens = len(encoding.encode(response))*n_responses\n",
    "print(prompt_tokens)\n",
    "print(response_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2d29875-2a96-4ca8-82c2-1ee2c0b43a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost is: 1.6980000000000002$\n"
     ]
    }
   ],
   "source": [
    "cost = n_samples*((prompt_tokens*prices[0] + response_tokens*prices[1])/1000000)\n",
    "print(\"The cost is: \"+str(cost)+\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8d97a-e0e4-4b54-97b6-d12f98cdc14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
